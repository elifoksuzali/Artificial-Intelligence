{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30de134-1604-4ef6-a37c-fe9c0a78baea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.constraints import max_norm as maxnorm # güncel kullanım şekilleri\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.constraints import max_norm # güncel kullanım şekilleri\n",
    "from tensorflow.keras.optimizers.legacy import SGD  # güncel kullanım şekilleri\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
    "# keras modlü eski sürümleri destekler bu yüzden keras yerine tensorflow kullanarak güncel kütüphane erişimi sağlanır\n",
    "from tensorflow.keras.utils import to_categorical # np_utils kullanımı artık yok onun yerine numpy ile kullanılıp to_categorical ile aynı kullanımı veriyor\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7168f0f2-9cd9-4028-b704-f2fe4d24a0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 852 images belonging to 4 classes.\n",
      "Found 148 images belonging to 4 classes.\n",
      "Found 1000 images belonging to 4 classes.\n",
      "Epoch 1/50\n",
      "27/27 [==============================] - 41s 1s/step - loss: 1.4955 - accuracy: 0.3275 - val_loss: 1.3603 - val_accuracy: 0.3581\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: 1.2726 - accuracy: 0.4143 - val_loss: 1.3102 - val_accuracy: 0.3986\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: 1.2126 - accuracy: 0.4718 - val_loss: 1.2637 - val_accuracy: 0.4122\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 35s 1s/step - loss: 1.1659 - accuracy: 0.4636 - val_loss: 1.1204 - val_accuracy: 0.5068\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: 1.1562 - accuracy: 0.4906 - val_loss: 1.1168 - val_accuracy: 0.4392\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: 1.1231 - accuracy: 0.4965 - val_loss: 1.1742 - val_accuracy: 0.4257\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 33s 1s/step - loss: 1.1620 - accuracy: 0.4789 - val_loss: 1.1144 - val_accuracy: 0.4662\n",
      "Epoch 8/50\n",
      "22/27 [=======================>......] - ETA: 5s - loss: 1.1143 - accuracy: 0.5213"
     ]
    }
   ],
   "source": [
    "# Veri seti klasörünün yolu (Data klasörünüzün yolu)\n",
    "data_dir = \"Datas\"\n",
    "\n",
    "# Veri setini yükleme ve ön işleme\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.15)\n",
    "\n",
    "# Eğitim ve doğrulama verilerini yükleme\n",
    "input_width, input_height = 150, 150\n",
    "batch_size = 32\n",
    "num_classes = 4  # Toplam sınıf sayısı\n",
    "\n",
    "train_data = datagen.flow_from_directory(data_dir, target_size=(input_width, input_height),\n",
    "                                        class_mode='categorical', batch_size=batch_size, subset='training')\n",
    "validation_data = datagen.flow_from_directory(data_dir, target_size=(input_width, input_height),\n",
    "                                             class_mode='categorical', batch_size=batch_size, subset='validation')\n",
    "\n",
    "# Eğitim sonrası test için kullanabilirsiniz\n",
    "test_data = datagen.flow_from_directory(data_dir, target_size=(input_width, input_height), class_mode='categorical',\n",
    "                                       batch_size=batch_size)\n",
    "# CNN modelini oluşturun\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(input_width, input_height, 3), padding='same',\n",
    "                 kernel_constraint=max_norm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=max_norm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=max_norm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# SGD optimizer'ı kullanarak modeli derleyin\n",
    "sgd = SGD(learning_rate=0.01,momentum=0.9,decay=(0.01/25),nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Modeli eğitin\n",
    "model.fit(train_data, validation_data=validation_data, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9a8f6b-75c0-4c1b-9f83-6950071b727e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 150, 150, 32)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 150, 150, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 75, 75, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 180000)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               92160512  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 92172708 (351.61 MB)\n",
      "Trainable params: 92172708 (351.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3653087f-8e7d-42f1-8de5-63ab54157a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 113ms/step - loss: 1.9406 - accuracy: 0.4662\n",
      "46.621620655059814\n"
     ]
    }
   ],
   "source": [
    "_,acc=model.evaluate(test_data)\n",
    "print(acc*100)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a34377-eb13-4f71-b352-bc3270c78dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model.save('cnn.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00a9ab89-19ea-4a5b-80e4-a3f8bbab94aa",
   "metadata": {},
   "source": [
    "# 1000 veri seti epoch = 50              acc = 64.32432174682617     bach_size = 32\n",
    "\n",
    "# 1000 veri seti epoch = 100             acc = 74.32432174682617    bach_size = 32\n",
    "\n",
    "# 1000 veri seti epoch = 150             acc = 71.32432174682617    bach_size = 32\n",
    "\n",
    "# 1000 veri seti epoch = 300             acc = 68.32432174682617    bach_size = 32"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebfe97ad-865a-4026-8fbc-9f752b516129",
   "metadata": {
    "tags": []
   },
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import numpy\n",
    "from keras.models import load_model\n",
    "model = load_model('cnn.h5')\n",
    "classes = { \n",
    "    0:'Dıştan Görünüm',\n",
    "    1:'İç Mekan',\n",
    "    2:'Odalar',\n",
    "    3:'Olanaklar'\n",
    "}\n",
    "top=tk.Tk()\n",
    "top.geometry('800x600')\n",
    "top.title('Deep Learning')\n",
    "top.configure(background='#CDCDCD')\n",
    "label=Label(top,background='#CDCDCD', font=('arial',15,'bold'))\n",
    "sign_image = Label(top)\n",
    "def classify(file_path):\n",
    "    global label_packed\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((32,32))\n",
    "    image = numpy.expand_dims(image, axis=0)\n",
    "    image = numpy.array(image)\n",
    "    pred=np.argmax(model.predict([image])[0],axis=-1)\n",
    "    sign = classes[pred]\n",
    "    print(pred)\n",
    "    label.configure(foreground='#011638', text=sign)     \n",
    "def show_classify_button(file_path):\n",
    "    classify_b=Button(top,text=\"Sınıflandır\",\n",
    "    command=lambda: classify(file_path),padx=10,pady=5)\n",
    "    classify_b.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "    classify_b.place(relx=0.79,rely=0.46)\n",
    "def upload_image():\n",
    "    try:\n",
    "        file_path=filedialog.askopenfilename()\n",
    "        uploaded=Image.open(file_path)\n",
    "        uploaded.thumbnail(((top.winfo_width()/2.25),(top.winfo_height()/2.25)))\n",
    "        im=ImageTk.PhotoImage(uploaded)\n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image=im\n",
    "        label.configure(text='')\n",
    "        show_classify_button(file_path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "upload=Button(top,text=\"Yükle\",command=upload_image,padx=10,pady=5)\n",
    "upload.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "upload.pack(side=BOTTOM,pady=50)\n",
    "sign_image.pack(side=BOTTOM,expand=True)\n",
    "label.pack(side=BOTTOM,expand=True)\n",
    "heading = Label(top, text=\"Deep Learning Projesi\",pady=20, font=('arial',20,'bold'))\n",
    "\n",
    "heading.configure(background='#CDCDCD',foreground='#364156')\n",
    "heading.pack()\n",
    "top.mainloop()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7cce0da-69cc-4150-a701-87e662424e5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Veri setinin en küçük görsel boyutunu öğrenme\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "    # Veri seti yolu\n",
    "data_dir = \"Datas\"\n",
    "\n",
    "      # En küçük boyutu bulmak için başlangıç değerleri\n",
    "min_width = float('inf')\n",
    "min_height = float('inf')\n",
    "min_image_path = None  # En küçük boyuta sahip görüntünün yolu\n",
    "\n",
    "     # Veri setindeki tüm görüntülerin boyutlarını kontrol edin ve en küçük boyutu bulun\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):  # Görüntü dosya uzantısına göre ayarlayın\n",
    "            file_path = os.path.join(root, file)\n",
    "            img = cv2.imread(file_path)\n",
    "            if img is not None:  # Görüntü başarıyla yüklendi mi kontrol edin\n",
    "                height, width, _ = img.shape\n",
    "                if height < min_height:\n",
    "                    min_height = height\n",
    "                    min_width = width\n",
    "                    min_image_path = file_path\n",
    "\n",
    "print(f\"En küçük boyut: Genişlik {min_width} x Yükseklik {min_height}\")\n",
    "print(f\"En küçük boyutlu görüntünün yolu: {min_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142bd863-5a85-412e-8431-ddf1b5d96103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
