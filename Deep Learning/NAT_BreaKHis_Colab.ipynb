{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî¨ NAT (Neighborhood Attention Transformer) - BreaKHis Dataset\n",
        "\n",
        "Bu notebook, BreaKHis meme kanseri histopatoloji veri seti √ºzerinde NAT modelini eƒüitir.\n",
        "\n",
        "**√ñzellikler:**\n",
        "- T√ºm magnification'lar (40X, 100X, 200X, 400X)\n",
        "- Patient-stratified split\n",
        "- Confusion Matrix, ROC-AUC, Precision, Recall, F1-Score\n",
        "- GPU optimizasyonlarƒ± (A100/T4/V100)\n",
        "\n",
        "---\n",
        "**‚ö†Ô∏è √ñNEMLƒ∞:** Runtime > Change runtime type > GPU (A100 veya T4) se√ßin!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 1Ô∏è‚É£ GPU Kontrol√º ve K√ºt√ºphaneler\n",
        "# =============================================================================\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\n‚úÖ PyTorch: {torch.__version__}\")\n",
        "print(f\"‚úÖ CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úÖ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "# Gerekli k√ºt√ºphaneleri y√ºkle\n",
        "%pip install -q kagglehub tqdm seaborn scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 2Ô∏è‚É£ Veri Setini ƒ∞ndir\n",
        "# =============================================================================\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "print(\"üì• Downloading BreaKHis dataset...\")\n",
        "dataset_path = kagglehub.dataset_download(\"ambarish/breakhis\")\n",
        "print(f\"‚úÖ Dataset downloaded to: {dataset_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 3Ô∏è‚É£ Imports ve Konfig√ºrasyon\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import GradScaler, autocast\n",
        "import torchvision.transforms as T\n",
        "from sklearn.metrics import (\n",
        "    classification_report, \n",
        "    confusion_matrix, \n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "\n",
        "# Seed\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üñ•Ô∏è Device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 4Ô∏è‚É£ Konfig√ºrasyon - Colab/A100 i√ßin Optimize\n",
        "# =============================================================================\n",
        "\n",
        "class Config:\n",
        "    # Veri seti yolu\n",
        "    BASE_PATH = Path(dataset_path) / \"BreaKHis_v1\" / \"BreaKHis_v1\" / \"histology_slides\" / \"breast\"\n",
        "    \n",
        "    # Eƒüitim parametreleri\n",
        "    SEED = 42\n",
        "    IMG_SIZE = 224\n",
        "    # A100: 64, T4/V100: 32, d√º≈ü√ºk VRAM: 16\n",
        "    BATCH_SIZE = 64 if torch.cuda.is_available() and torch.cuda.get_device_properties(0).total_memory > 30e9 else 32\n",
        "    NUM_WORKERS = 2  # Colab i√ßin\n",
        "    EPOCHS = 20  # Ba≈ülangƒ±√ß i√ßin yeterli\n",
        "    LEARNING_RATE = 1e-4\n",
        "    WEIGHT_DECAY = 0.05\n",
        "    \n",
        "    # Model\n",
        "    NUM_CLASSES = 2\n",
        "    CLASS_NAMES = ['benign', 'malignant']\n",
        "    MODEL_VARIANT = 'tiny'\n",
        "    \n",
        "    # Magnification - T√ºm√º\n",
        "    MAGNIFICATIONS = ['40X', '100X', '200X', '400X']\n",
        "    SELECTED_MAG = 'ALL'\n",
        "    \n",
        "    # Early stopping\n",
        "    PATIENCE = 10\n",
        "    USE_AMP = True\n",
        "    \n",
        "    DEVICE = DEVICE\n",
        "\n",
        "config = Config()\n",
        "print(f\"üìä Batch Size: {config.BATCH_SIZE}\")\n",
        "print(f\"üìä Epochs: {config.EPOCHS}\")\n",
        "print(f\"üìä Image Size: {config.IMG_SIZE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 5Ô∏è‚É£ NAT (Neighborhood Attention Transformer) Model\n",
        "# =============================================================================\n",
        "\n",
        "class NeighborhoodAttention2D(nn.Module):\n",
        "    \"\"\"Efficient 2D Neighborhood Attention\"\"\"\n",
        "    \n",
        "    def __init__(self, dim, num_heads, kernel_size=7, dilation=1, qkv_bias=True, attn_drop=0.0, proj_drop=0.0):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.padding = (kernel_size // 2) * dilation\n",
        "        \n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.rpb = nn.Parameter(torch.zeros(num_heads, kernel_size * kernel_size))\n",
        "        nn.init.trunc_normal_(self.rpb, std=0.02)\n",
        "        \n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        B, H, W, C = x.shape\n",
        "        \n",
        "        qkv = self.qkv(x).reshape(B, H, W, 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.permute(3, 0, 4, 5, 1, 2)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        \n",
        "        q = q * self.scale\n",
        "        \n",
        "        k = F.pad(k, (self.padding,) * 4, mode='constant', value=0)\n",
        "        v = F.pad(v, (self.padding,) * 4, mode='constant', value=0)\n",
        "        \n",
        "        k = k.unfold(3, self.kernel_size, 1).unfold(4, self.kernel_size, 1)\n",
        "        v = v.unfold(3, self.kernel_size, 1).unfold(4, self.kernel_size, 1)\n",
        "        \n",
        "        k = k.reshape(B, self.num_heads, self.head_dim, H, W, -1)\n",
        "        v = v.reshape(B, self.num_heads, self.head_dim, H, W, -1)\n",
        "        \n",
        "        q = q.permute(0, 1, 3, 4, 2).unsqueeze(-2)\n",
        "        k = k.permute(0, 1, 3, 4, 2, 5)\n",
        "        v = v.permute(0, 1, 3, 4, 2, 5)\n",
        "        \n",
        "        attn = q @ k\n",
        "        attn = attn + self.rpb.view(1, self.num_heads, 1, 1, 1, -1)\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "        \n",
        "        out = attn @ v.transpose(-2, -1)\n",
        "        out = out.squeeze(-2).permute(0, 2, 3, 1, 4).reshape(B, H, W, C)\n",
        "        \n",
        "        out = self.proj(out)\n",
        "        out = self.proj_drop(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0.0):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DropPath(nn.Module):\n",
        "    def __init__(self, drop_prob=0.0):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if self.drop_prob == 0.0 or not self.training:\n",
        "            return x\n",
        "        keep_prob = 1 - self.drop_prob\n",
        "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
        "        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
        "        random_tensor.floor_()\n",
        "        return x.div(keep_prob) * random_tensor\n",
        "\n",
        "\n",
        "class NATBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, kernel_size=7, dilation=1, mlp_ratio=4.0, \n",
        "                 qkv_bias=True, drop=0.0, attn_drop=0.0, drop_path=0.0):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = NeighborhoodAttention2D(dim, num_heads, kernel_size, dilation, qkv_bias, attn_drop, drop)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.mlp = Mlp(dim, int(dim * mlp_ratio), drop=drop)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, in_chans=3, embed_dim=64, patch_size=4):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = self.norm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PatchMerging(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
        "        self.norm = nn.LayerNorm(4 * dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        B, H, W, C = x.shape\n",
        "        if H % 2 == 1 or W % 2 == 1:\n",
        "            x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))\n",
        "            B, H, W, C = x.shape\n",
        "        x0 = x[:, 0::2, 0::2, :]\n",
        "        x1 = x[:, 1::2, 0::2, :]\n",
        "        x2 = x[:, 0::2, 1::2, :]\n",
        "        x3 = x[:, 1::2, 1::2, :]\n",
        "        x = torch.cat([x0, x1, x2, x3], dim=-1)\n",
        "        x = self.norm(x)\n",
        "        x = self.reduction(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class NATStage(nn.Module):\n",
        "    def __init__(self, dim, depth, num_heads, kernel_size=7, dilations=None, \n",
        "                 downsample=True, mlp_ratio=4.0, qkv_bias=True, drop=0.0, attn_drop=0.0, drop_path=None):\n",
        "        super().__init__()\n",
        "        dilations = dilations or [1] * depth\n",
        "        drop_path = drop_path or [0.0] * depth\n",
        "        \n",
        "        self.blocks = nn.ModuleList([\n",
        "            NATBlock(dim, num_heads, kernel_size, dilations[i], mlp_ratio, qkv_bias, drop, attn_drop, drop_path[i])\n",
        "            for i in range(depth)\n",
        "        ])\n",
        "        self.downsample = PatchMerging(dim) if downsample else None\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "        if self.downsample is not None:\n",
        "            x = self.downsample(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class NAT(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=4, in_chans=3, num_classes=2,\n",
        "                 embed_dim=64, depths=[2, 2, 6, 2], num_heads=[2, 4, 8, 16],\n",
        "                 kernel_size=7, mlp_ratio=4.0, qkv_bias=True,\n",
        "                 drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.2):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.num_stages = len(depths)\n",
        "        self.num_features = embed_dim * (2 ** (self.num_stages - 1))\n",
        "        \n",
        "        self.patch_embed = PatchEmbed(in_chans, embed_dim, patch_size)\n",
        "        \n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
        "        \n",
        "        self.stages = nn.ModuleList()\n",
        "        for i in range(self.num_stages):\n",
        "            stage = NATStage(\n",
        "                dim=embed_dim * (2 ** i),\n",
        "                depth=depths[i],\n",
        "                num_heads=num_heads[i],\n",
        "                kernel_size=kernel_size,\n",
        "                downsample=(i < self.num_stages - 1),\n",
        "                mlp_ratio=mlp_ratio,\n",
        "                qkv_bias=qkv_bias,\n",
        "                drop=drop_rate,\n",
        "                attn_drop=attn_drop_rate,\n",
        "                drop_path=dpr[sum(depths[:i]):sum(depths[:i+1])],\n",
        "            )\n",
        "            self.stages.append(stage)\n",
        "        \n",
        "        self.norm = nn.LayerNorm(self.num_features)\n",
        "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.head = nn.Linear(self.num_features, num_classes)\n",
        "        \n",
        "        self.apply(self._init_weights)\n",
        "        \n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "                \n",
        "    def forward(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        for stage in self.stages:\n",
        "            x = stage(x)\n",
        "        x = self.norm(x)\n",
        "        x = x.permute(0, 3, 1, 2).flatten(2)\n",
        "        x = self.avgpool(x).flatten(1)\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def nat_tiny(num_classes=2):\n",
        "    return NAT(embed_dim=64, depths=[3, 4, 6, 5], num_heads=[2, 4, 8, 16], num_classes=num_classes)\n",
        "\n",
        "def nat_mini(num_classes=2):\n",
        "    return NAT(embed_dim=64, depths=[2, 2, 6, 2], num_heads=[2, 4, 8, 16], num_classes=num_classes)\n",
        "\n",
        "print(\"‚úÖ NAT Model defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 6Ô∏è‚É£ Veri Seti Hazƒ±rlama\n",
        "# =============================================================================\n",
        "\n",
        "def parse_breakhis_path(filepath):\n",
        "    fname = os.path.basename(filepath)\n",
        "    parts = fname.split('_')\n",
        "    label_token = parts[1] if len(parts) > 1 else ''\n",
        "    label = 'benign' if label_token.upper().startswith('B') else 'malignant'\n",
        "    mag = Path(filepath).parents[0].name\n",
        "    try:\n",
        "        patient = parts[2].rsplit('-', 2)[0]\n",
        "    except:\n",
        "        m = re.search(r'([A-Za-z]-\\d+-\\w+)', fname)\n",
        "        patient = m.group(1) if m else fname\n",
        "    return label, mag, patient\n",
        "\n",
        "\n",
        "def create_dataframe(base_path):\n",
        "    image_paths = sorted([str(p) for p in Path(base_path).rglob('*.png')])\n",
        "    rows = []\n",
        "    for p in image_paths:\n",
        "        label, mag, patient = parse_breakhis_path(p)\n",
        "        rows.append({'filepath': p, 'label': label, 'mag': mag.upper().replace(' ', ''), 'patient_id': patient})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "def patient_stratified_split(df, train_frac=0.7, val_frac=0.1, test_frac=0.2, seed=42):\n",
        "    patients = df['patient_id'].unique().tolist()\n",
        "    random.Random(seed).shuffle(patients)\n",
        "    n = len(patients)\n",
        "    n_train = int(round(train_frac * n))\n",
        "    n_val = int(round(val_frac * n))\n",
        "    \n",
        "    train_patients = set(patients[:n_train])\n",
        "    val_patients = set(patients[n_train:n_train + n_val])\n",
        "    test_patients = set(patients[n_train + n_val:])\n",
        "    \n",
        "    return {\n",
        "        'train': df[df['patient_id'].isin(train_patients)].reset_index(drop=True),\n",
        "        'val': df[df['patient_id'].isin(val_patients)].reset_index(drop=True),\n",
        "        'test': df[df['patient_id'].isin(test_patients)].reset_index(drop=True)\n",
        "    }\n",
        "\n",
        "\n",
        "# DataFrame olu≈ütur\n",
        "df = create_dataframe(config.BASE_PATH)\n",
        "print(f\"üìä Total images: {len(df)}\")\n",
        "\n",
        "# Magnification daƒüƒ±lƒ±mƒ±\n",
        "print(f\"\\nüìä Magnification distribution:\")\n",
        "for mag in config.MAGNIFICATIONS:\n",
        "    count = len(df[df['mag'] == mag])\n",
        "    print(f\"   - {mag}: {count}\")\n",
        "\n",
        "# Class daƒüƒ±lƒ±mƒ±\n",
        "print(f\"\\nüìä Class distribution:\")\n",
        "for cls in config.CLASS_NAMES:\n",
        "    count = len(df[df['label'] == cls])\n",
        "    print(f\"   - {cls}: {count} ({100*count/len(df):.1f}%)\")\n",
        "\n",
        "# Patient-stratified split\n",
        "splits = patient_stratified_split(df, 0.7, 0.1, 0.2, config.SEED)\n",
        "print(f\"\\nüìä Splits:\")\n",
        "for name, split_df in splits.items():\n",
        "    print(f\"   - {name}: {len(split_df)} images, {split_df['patient_id'].nunique()} patients\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 7Ô∏è‚É£ Dataset & DataLoader\n",
        "# =============================================================================\n",
        "\n",
        "class BreaKHisDataset(Dataset):\n",
        "    def __init__(self, df, transform=None, class_names=['benign', 'malignant']):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = {c: i for i, c in enumerate(class_names)}\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image = Image.open(row['filepath']).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.class_to_idx[row['label']]\n",
        "        return image, label\n",
        "\n",
        "\n",
        "def get_transforms(img_size=224, is_training=True):\n",
        "    if is_training:\n",
        "        return T.Compose([\n",
        "            T.Resize((img_size + 32, img_size + 32)),\n",
        "            T.RandomCrop(img_size),\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip(),\n",
        "            T.RandomRotation(15),\n",
        "            T.ColorJitter(0.2, 0.2, 0.1, 0.05),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "    else:\n",
        "        return T.Compose([\n",
        "            T.Resize((img_size, img_size)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "\n",
        "# DataLoader'lar\n",
        "train_ds = BreaKHisDataset(splits['train'], get_transforms(config.IMG_SIZE, True), config.CLASS_NAMES)\n",
        "val_ds = BreaKHisDataset(splits['val'], get_transforms(config.IMG_SIZE, False), config.CLASS_NAMES)\n",
        "test_ds = BreaKHisDataset(splits['test'], get_transforms(config.IMG_SIZE, False), config.CLASS_NAMES)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=config.NUM_WORKERS, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=config.NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "# Class weights\n",
        "class_counts = splits['train']['label'].value_counts()\n",
        "total = len(splits['train'])\n",
        "class_weights = torch.tensor([total / (2 * class_counts.get(cls, 1)) for cls in config.CLASS_NAMES], dtype=torch.float32)\n",
        "class_weights = class_weights.to(config.DEVICE)\n",
        "\n",
        "print(f\"‚úÖ DataLoaders created!\")\n",
        "print(f\"   Train batches: {len(train_loader)}, Val batches: {len(val_loader)}, Test batches: {len(test_loader)}\")\n",
        "print(f\"   Class weights: {class_weights.cpu().numpy()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 8Ô∏è‚É£ Model Olu≈ütur ve Eƒüit\n",
        "# =============================================================================\n",
        "\n",
        "# Model\n",
        "model = nat_tiny(num_classes=config.NUM_CLASSES).to(config.DEVICE)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"üèóÔ∏è NAT Model - Total params: {total_params:,}\")\n",
        "\n",
        "# Loss, Optimizer, Scheduler\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.EPOCHS, eta_min=1e-6)\n",
        "scaler = GradScaler('cuda') if config.USE_AMP else None\n",
        "\n",
        "# History\n",
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': [], 'val_auc': []}\n",
        "best_val_f1 = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "print(\"üöÄ Starting training...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for epoch in range(config.EPOCHS):\n",
        "    # TRAIN\n",
        "    model.train()\n",
        "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Train]\")\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(config.DEVICE), labels.to(config.DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if config.USE_AMP:\n",
        "            with autocast('cuda'):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += predicted.eq(labels).sum().item()\n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*train_correct/train_total:.2f}%'})\n",
        "    \n",
        "    train_loss /= train_total\n",
        "    train_acc = train_correct / train_total\n",
        "    \n",
        "    # VALIDATE\n",
        "    model.eval()\n",
        "    val_loss, val_preds, val_labels, val_probs = 0.0, [], [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config.EPOCHS} [Val]\"):\n",
        "            images, labels = images.to(config.DEVICE), labels.to(config.DEVICE)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            \n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_preds.extend(predicted.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "            val_probs.extend(probs[:, 1].cpu().numpy())\n",
        "    \n",
        "    val_loss /= len(val_labels)\n",
        "    val_acc = accuracy_score(val_labels, val_preds)\n",
        "    _, _, val_f1, _ = precision_recall_fscore_support(val_labels, val_preds, average='weighted', zero_division=0)\n",
        "    try:\n",
        "        val_auc = roc_auc_score(val_labels, val_probs)\n",
        "    except:\n",
        "        val_auc = 0.0\n",
        "    \n",
        "    scheduler.step()\n",
        "    \n",
        "    # History\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_f1'].append(val_f1)\n",
        "    history['val_auc'].append(val_auc)\n",
        "    \n",
        "    print(f\"\\nüìä Epoch {epoch+1}: Train Loss={train_loss:.4f}, Acc={100*train_acc:.2f}% | Val Loss={val_loss:.4f}, Acc={100*val_acc:.2f}%, F1={100*val_f1:.2f}%, AUC={100*val_auc:.2f}%\")\n",
        "    \n",
        "    # Best model\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'nat_best_model.pth')\n",
        "        print(f\"   ‚úÖ Best model saved! (F1: {100*best_val_f1:.2f}%)\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= config.PATIENCE:\n",
        "            print(f\"\\n‚ö†Ô∏è Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(f\"‚úÖ Training complete! Best Val F1: {100*best_val_f1:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 9Ô∏è‚É£ Eƒüitim Grafikleri\n",
        "# =============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "axes[0, 0].plot(history['train_loss'], label='Train', lw=2)\n",
        "axes[0, 0].plot(history['val_loss'], label='Val', lw=2)\n",
        "axes[0, 0].set_title('Loss', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0, 1].plot(history['train_acc'], label='Train', lw=2)\n",
        "axes[0, 1].plot(history['val_acc'], label='Val', lw=2)\n",
        "axes[0, 1].set_title('Accuracy', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 0].plot(history['val_f1'], label='Val F1', lw=2, color='green')\n",
        "axes[1, 0].set_title('Validation F1-Score', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 1].plot(history['val_auc'], label='Val AUC', lw=2, color='purple')\n",
        "axes[1, 1].set_title('Validation AUC-ROC', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png', dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# üîü Test Deƒüerlendirmesi\n",
        "# =============================================================================\n",
        "\n",
        "# En iyi modeli y√ºkle\n",
        "model.load_state_dict(torch.load('nat_best_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "test_preds, test_labels_list, test_probs = [], [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "        images = images.to(config.DEVICE)\n",
        "        outputs = model(images)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        _, predicted = outputs.max(1)\n",
        "        \n",
        "        test_preds.extend(predicted.cpu().numpy())\n",
        "        test_labels_list.extend(labels.numpy())\n",
        "        test_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "test_preds = np.array(test_preds)\n",
        "test_labels_arr = np.array(test_labels_list)\n",
        "test_probs = np.array(test_probs)\n",
        "\n",
        "# Metrikler\n",
        "accuracy = accuracy_score(test_labels_arr, test_preds)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_labels_arr, test_preds, average='weighted')\n",
        "auc = roc_auc_score(test_labels_arr, test_probs[:, 1])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\" TEST RESULTS \")\n",
        "print(\"=\" * 70)\n",
        "print(f\"   Accuracy:  {100*accuracy:.2f}%\")\n",
        "print(f\"   Precision: {100*precision:.2f}%\")\n",
        "print(f\"   Recall:    {100*recall:.2f}%\")\n",
        "print(f\"   F1-Score:  {100*f1:.2f}%\")\n",
        "print(f\"   AUC-ROC:   {100*auc:.2f}%\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nüìã Classification Report:\")\n",
        "print(classification_report(test_labels_arr, test_preds, target_names=config.CLASS_NAMES, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£ Confusion Matrix & ROC Curve\n",
        "# =============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(test_labels_arr, test_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            xticklabels=config.CLASS_NAMES, yticklabels=config.CLASS_NAMES,\n",
        "            annot_kws={'size': 16, 'weight': 'bold'})\n",
        "axes[0].set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
        "axes[0].set_ylabel('True', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(test_labels_arr, test_probs[:, 1])\n",
        "axes[1].plot(fpr, tpr, color='#3498db', lw=2, label=f'ROC (AUC = {auc:.4f})')\n",
        "axes[1].plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "axes[1].fill_between(fpr, tpr, alpha=0.3)\n",
        "axes[1].set_xlim([0.0, 1.0])\n",
        "axes[1].set_ylim([0.0, 1.05])\n",
        "axes[1].set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
        "axes[1].legend(loc='lower right')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_roc.png', dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 1Ô∏è‚É£2Ô∏è‚É£ Per-Magnification Sonu√ßlarƒ±\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nüìä Per-Magnification Results:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Mag':<10} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1':<12} {'Support':<10}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "results_per_mag = {}\n",
        "\n",
        "for mag in config.MAGNIFICATIONS:\n",
        "    df_mag = splits['test'][splits['test']['mag'] == mag]\n",
        "    if len(df_mag) == 0:\n",
        "        continue\n",
        "    \n",
        "    ds = BreaKHisDataset(df_mag, get_transforms(config.IMG_SIZE, False), config.CLASS_NAMES)\n",
        "    loader = DataLoader(ds, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "    \n",
        "    preds, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, lbls in loader:\n",
        "            outputs = model(images.to(config.DEVICE))\n",
        "            _, predicted = outputs.max(1)\n",
        "            preds.extend(predicted.cpu().numpy())\n",
        "            labels.extend(lbls.numpy())\n",
        "    \n",
        "    acc = accuracy_score(labels, preds)\n",
        "    prec, rec, f1_sc, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
        "    \n",
        "    results_per_mag[mag] = {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1_sc, 'support': len(df_mag)}\n",
        "    print(f\"{mag:<10} {100*acc:<12.2f} {100*prec:<12.2f} {100*rec:<12.2f} {100*f1_sc:<12.2f} {len(df_mag):<10}\")\n",
        "\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Bar Chart\n",
        "mags = list(results_per_mag.keys())\n",
        "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
        "colors = ['#3498db', '#2ecc71', '#f39c12', '#e74c3c']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "x = np.arange(len(mags))\n",
        "width = 0.2\n",
        "\n",
        "for i, (metric, color) in enumerate(zip(metrics, colors)):\n",
        "    values = [results_per_mag[mag][metric] for mag in mags]\n",
        "    ax.bar(x + i * width, values, width, label=metric.capitalize(), color=color)\n",
        "\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "ax.set_title('Performance by Magnification', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x + width * 1.5)\n",
        "ax.set_xticklabels(mags)\n",
        "ax.legend()\n",
        "ax.set_ylim(0, 1.1)\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('per_magnification.png', dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# 1Ô∏è‚É£3Ô∏è‚É£ Modeli Google Drive'a Kaydet (Opsiyonel)\n",
        "# =============================================================================\n",
        "\n",
        "# Google Drive'ƒ± baƒüla\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Sonu√ßlarƒ± kaydet\n",
        "import shutil\n",
        "save_dir = '/content/drive/MyDrive/NAT_BreaKHis_Results/'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "shutil.copy('nat_best_model.pth', save_dir)\n",
        "shutil.copy('training_history.png', save_dir)\n",
        "shutil.copy('confusion_roc.png', save_dir)\n",
        "shutil.copy('per_magnification.png', save_dir)\n",
        "\n",
        "print(f\"‚úÖ All results saved to: {save_dir}\")\n",
        "print(\"\\nüìÅ Files saved:\")\n",
        "for f in os.listdir(save_dir):\n",
        "    print(f\"   - {f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ‚úÖ Tamamlandƒ±!\n",
        "\n",
        "### üìä Sonu√ßlar:\n",
        "- `nat_best_model.pth` - Eƒüitilmi≈ü NAT model\n",
        "- `training_history.png` - Eƒüitim grafikleri (Loss, Accuracy, F1, AUC)\n",
        "- `confusion_roc.png` - Confusion Matrix & ROC Curve\n",
        "- `per_magnification.png` - 40X, 100X, 200X, 400X kar≈üƒ±la≈ütƒ±rma\n",
        "\n",
        "### üöÄ Kullanƒ±m:\n",
        "```python\n",
        "# Modeli y√ºkle\n",
        "model = nat_tiny(num_classes=2)\n",
        "model.load_state_dict(torch.load('nat_best_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Tahmin yap\n",
        "output = model(image_tensor)\n",
        "prediction = output.argmax(dim=1)\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
