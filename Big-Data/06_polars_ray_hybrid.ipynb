{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Polars + Ray: En Ä°yi Ä°ki DÃ¼nya\n",
    "\n",
    "Bu notebook'ta **Polars** ve **Ray**'i birlikte kullanarak optimal bir pipeline oluÅŸturacaÄŸÄ±z.\n",
    "\n",
    "**Strateji:**\n",
    "- **Polars**: HÄ±zlÄ± veri yÃ¼kleme, temizleme ve feature engineering (5-10x Pandas)\n",
    "- **Ray**: Paralel model training ve hyperparameter tuning\n",
    "\n",
    "**Neden Bu Kombinasyon?**\n",
    "- Polars: Single-node'da en hÄ±zlÄ± DataFrame kÃ¼tÃ¼phanesi\n",
    "- Ray: Distributed computing ve ML paralellestirme\n",
    "- Birlikte: End-to-end optimum performans\n",
    "\n",
    "**Veri Seti:** NYC Yellow Taxi 2023 (12 ay, ~40M satÄ±r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kurulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kÃ¼tÃ¼phaneler\n",
    "!pip install polars ray scikit-learn xgboost pyarrow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars version: 1.31.0\n",
      "Ray version: 2.52.1\n",
      "CPU count: 12\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import ray\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "print(f\"Polars version: {pl.__version__}\")\n",
    "print(f\"Ray version: {ray.__version__}\")\n",
    "print(f\"CPU count: {os.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark fonksiyonlarÄ±\n",
    "results = {\n",
    "    'framework': 'polars_ray_hybrid',\n",
    "    'dataset': 'nyc_taxi_12_months',\n",
    "    'operations': {}\n",
    "}\n",
    "\n",
    "def get_memory_mb():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "def benchmark(func, name):\n",
    "    gc.collect()\n",
    "    mem_before = get_memory_mb()\n",
    "    start = time.time()\n",
    "    result = func()\n",
    "    end = time.time()\n",
    "    mem_after = get_memory_mb()\n",
    "    \n",
    "    duration = end - start\n",
    "    mem_used = mem_after - mem_before\n",
    "    \n",
    "    results['operations'][name] = {\n",
    "        'duration_sec': round(duration, 3),\n",
    "        'memory_mb': round(mem_used, 2)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"âœ“ {name}\")\n",
    "    print(f\"  SÃ¼re: {duration:.3f} saniye\")\n",
    "    print(f\"  Bellek: {mem_used:.2f} MB\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mevcut: yellow_tripdata_2023-01.parquet\n",
      "Mevcut: yellow_tripdata_2023-02.parquet\n",
      "Mevcut: yellow_tripdata_2023-03.parquet\n",
      "Mevcut: yellow_tripdata_2023-04.parquet\n",
      "Mevcut: yellow_tripdata_2023-05.parquet\n",
      "Mevcut: yellow_tripdata_2023-06.parquet\n",
      "Mevcut: yellow_tripdata_2023-07.parquet\n",
      "Mevcut: yellow_tripdata_2023-08.parquet\n",
      "Mevcut: yellow_tripdata_2023-09.parquet\n",
      "Mevcut: yellow_tripdata_2023-10.parquet\n",
      "Mevcut: yellow_tripdata_2023-11.parquet\n",
      "Mevcut: yellow_tripdata_2023-12.parquet\n",
      "\n",
      "Toplam dosya boyutu: 606.3 MB\n",
      "Dosya sayÄ±sÄ±: 12\n"
     ]
    }
   ],
   "source": [
    "# Veri indirme - 12 ay\n",
    "DATA_DIR = 'data'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "MONTHS = ['2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06',\n",
    "          '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12']\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{}.parquet\"\n",
    "\n",
    "taxi_files = []\n",
    "total_size = 0\n",
    "\n",
    "for month in MONTHS:\n",
    "    filename = f\"yellow_tripdata_{month}.parquet\"\n",
    "    filepath = os.path.join(DATA_DIR, filename)\n",
    "    taxi_files.append(filepath)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        url = BASE_URL.format(month)\n",
    "        print(f\"Ä°ndiriliyor: {filename}...\")\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "        print(f\"Ä°ndirildi: {filename}\")\n",
    "    else:\n",
    "        print(f\"Mevcut: {filename}\")\n",
    "    \n",
    "    total_size += os.path.getsize(filepath)\n",
    "\n",
    "print(f\"\\nToplam dosya boyutu: {total_size / 1024**2:.1f} MB\")\n",
    "print(f\"Dosya sayÄ±sÄ±: {len(taxi_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Polars ile HÄ±zlÄ± Veri YÃ¼kleme (Lazy Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "âœ“ polars_lazy_scan\n",
      "  SÃ¼re: 0.003 saniye\n",
      "  Bellek: 0.00 MB\n",
      "==================================================\n",
      "\n",
      "Toplam satÄ±r: 3,066,766\n",
      "Schema: Schema({'VendorID': Int64, 'tpep_pickup_datetime': Datetime(time_unit='ns', time_zone=None), 'tpep_dropoff_datetime': Datetime(time_unit='ns', time_zone=None), 'passenger_count': Float64, 'trip_distance': Float64, 'RatecodeID': Float64, 'store_and_fwd_flag': String, 'PULocationID': Int64, 'DOLocationID': Int64, 'payment_type': Int64, 'fare_amount': Float64, 'extra': Float64, 'mta_tax': Float64, 'tip_amount': Float64, 'tolls_amount': Float64, 'improvement_surcharge': Float64, 'total_amount': Float64, 'congestion_surcharge': Float64, 'airport_fee': Float64})\n"
     ]
    }
   ],
   "source": [
    "# Polars Lazy: Sadece Ocak 2023 verisi (04 ile aynÄ± veri)\n",
    "def load_with_polars_lazy():\n",
    "    # Sadece ilk dosyayÄ± (Ocak 2023) yÃ¼kle - 04 notebook ile aynÄ±\n",
    "    lf = pl.scan_parquet(taxi_files[0])  # Ocak 2023\n",
    "    \n",
    "    # SatÄ±r sayÄ±sÄ±nÄ± al\n",
    "    row_count = lf.select(pl.len()).collect().item()\n",
    "\n",
    "    return lf, row_count\n",
    "\n",
    "lf, total_rows = benchmark(load_with_polars_lazy, 'polars_lazy_scan')\n",
    "print(f\"\\nToplam satÄ±r: {total_rows:,}\")\n",
    "print(f\"Schema: {lf.collect_schema()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "âœ“ polars_aggregations\n",
      "  SÃ¼re: 0.151 saniye\n",
      "  Bellek: 0.05 MB\n",
      "==================================================\n",
      "\n",
      "12 AylÄ±k Ã–zet Ä°statistikler:\n",
      "shape: (1, 5)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ avg_fare  â”† avg_distance â”† avg_tip  â”† total_revenue â”† avg_passengers â”‚\n",
      "â”‚ ---       â”† ---          â”† ---      â”† ---           â”† ---            â”‚\n",
      "â”‚ f64       â”† f64          â”† f64      â”† f64           â”† f64            â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 18.367069 â”† 3.847342     â”† 3.367941 â”† 8.2865e7      â”† 1.362532       â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Polars ile hÄ±zlÄ± istatistikler (lazy evaluation)\n",
    "def polars_quick_stats():\n",
    "    stats = lf.select([\n",
    "        pl.col('fare_amount').mean().alias('avg_fare'),\n",
    "        pl.col('trip_distance').mean().alias('avg_distance'),\n",
    "        pl.col('tip_amount').mean().alias('avg_tip'),\n",
    "        pl.col('total_amount').sum().alias('total_revenue'),\n",
    "        pl.col('passenger_count').mean().alias('avg_passengers')\n",
    "    ]).collect()\n",
    "    return stats\n",
    "\n",
    "stats = benchmark(polars_quick_stats, 'polars_aggregations')\n",
    "print(\"\\n12 AylÄ±k Ã–zet Ä°statistikler:\")\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Polars ile Feature Engineering\n",
    "\n",
    "Polars'Ä±n expression API'si ile hÄ±zlÄ± feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "âœ“ polars_feature_engineering\n",
      "  SÃ¼re: 0.150 saniye\n",
      "  Bellek: 0.43 MB\n",
      "==================================================\n",
      "\n",
      "Feature DataFrame: (2883426, 10)\n",
      "SÃ¼tunlar: ['tpep_pickup_datetime', 'trip_distance', 'PULocationID', 'DOLocationID', 'passenger_count', 'fare_amount', 'pickup_hour', 'pickup_dayofweek', 'is_weekend', 'is_rush_hour']\n"
     ]
    }
   ],
   "source": [
    "def polars_feature_engineering():\n",
    "    \"\"\"\n",
    "    Polars ile feature engineering - 04 notebook ile AYNI feature'lar.\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        lf\n",
    "        # Sadece gerekli sÃ¼tunlarÄ± seÃ§\n",
    "        .select([\n",
    "            'tpep_pickup_datetime',\n",
    "            'trip_distance',\n",
    "            'PULocationID',\n",
    "            'DOLocationID', \n",
    "            'passenger_count',\n",
    "            'fare_amount',\n",
    "        ])\n",
    "        # Filtreleme (04 ile aynÄ±)\n",
    "        .filter(\n",
    "            (pl.col('fare_amount') > 0) &\n",
    "            (pl.col('fare_amount') < 200) &\n",
    "            (pl.col('trip_distance') > 0) &\n",
    "            (pl.col('trip_distance') < 50) &\n",
    "            (pl.col('passenger_count') > 0) &\n",
    "            (pl.col('passenger_count').is_not_null())\n",
    "        )\n",
    "        # Feature extraction (04 ile AYNI)\n",
    "        .with_columns([\n",
    "            pl.col('tpep_pickup_datetime').dt.hour().alias('pickup_hour'),\n",
    "            pl.col('tpep_pickup_datetime').dt.weekday().alias('pickup_dayofweek'),\n",
    "        ])\n",
    "        # Derived features (04 ile AYNI)\n",
    "        .with_columns([\n",
    "            (pl.col('pickup_dayofweek') >= 5).cast(pl.Int8).alias('is_weekend'),\n",
    "            (\n",
    "                ((pl.col('pickup_hour') >= 7) & (pl.col('pickup_hour') <= 9)) |\n",
    "                ((pl.col('pickup_hour') >= 17) & (pl.col('pickup_hour') <= 19))\n",
    "            ).cast(pl.Int8).alias('is_rush_hour'),\n",
    "        ])\n",
    "        .collect()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_features = benchmark(polars_feature_engineering, 'polars_feature_engineering')\n",
    "print(f\"\\nFeature DataFrame: {df_features.shape}\")\n",
    "print(f\"SÃ¼tunlar: {df_features.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Veri Ã–rneÄŸi:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>tpep_pickup_datetime</th><th>trip_distance</th><th>PULocationID</th><th>DOLocationID</th><th>passenger_count</th><th>fare_amount</th><th>pickup_hour</th><th>pickup_dayofweek</th><th>is_weekend</th><th>is_rush_hour</th></tr><tr><td>datetime[ns]</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>2023-01-01 00:32:10</td><td>0.97</td><td>161</td><td>141</td><td>1.0</td><td>9.3</td><td>0</td><td>7</td><td>1</td><td>0</td></tr><tr><td>2023-01-01 00:55:08</td><td>1.1</td><td>43</td><td>237</td><td>1.0</td><td>7.9</td><td>0</td><td>7</td><td>1</td><td>0</td></tr><tr><td>2023-01-01 00:25:04</td><td>2.51</td><td>48</td><td>238</td><td>1.0</td><td>14.9</td><td>0</td><td>7</td><td>1</td><td>0</td></tr><tr><td>2023-01-01 00:10:29</td><td>1.43</td><td>107</td><td>79</td><td>1.0</td><td>11.4</td><td>0</td><td>7</td><td>1</td><td>0</td></tr><tr><td>2023-01-01 00:50:34</td><td>1.84</td><td>161</td><td>137</td><td>1.0</td><td>12.8</td><td>0</td><td>7</td><td>1</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ tpep_pick â”† trip_dist â”† PULocatio â”† DOLocatio â”† â€¦ â”† pickup_ho â”† pickup_da â”† is_weeken â”† is_rush_ â”‚\n",
       "â”‚ up_dateti â”† ance      â”† nID       â”† nID       â”†   â”† ur        â”† yofweek   â”† d         â”† hour     â”‚\n",
       "â”‚ me        â”† ---       â”† ---       â”† ---       â”†   â”† ---       â”† ---       â”† ---       â”† ---      â”‚\n",
       "â”‚ ---       â”† f64       â”† i64       â”† i64       â”†   â”† i8        â”† i8        â”† i8        â”† i8       â”‚\n",
       "â”‚ datetime[ â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ ns]       â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 2023-01-0 â”† 0.97      â”† 161       â”† 141       â”† â€¦ â”† 0         â”† 7         â”† 1         â”† 0        â”‚\n",
       "â”‚ 1         â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 00:32:10  â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 2023-01-0 â”† 1.1       â”† 43        â”† 237       â”† â€¦ â”† 0         â”† 7         â”† 1         â”† 0        â”‚\n",
       "â”‚ 1         â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 00:55:08  â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 2023-01-0 â”† 2.51      â”† 48        â”† 238       â”† â€¦ â”† 0         â”† 7         â”† 1         â”† 0        â”‚\n",
       "â”‚ 1         â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 00:25:04  â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 2023-01-0 â”† 1.43      â”† 107       â”† 79        â”† â€¦ â”† 0         â”† 7         â”† 1         â”† 0        â”‚\n",
       "â”‚ 1         â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 00:10:29  â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 2023-01-0 â”† 1.84      â”† 161       â”† 137       â”† â€¦ â”† 0         â”† 7         â”† 1         â”† 0        â”‚\n",
       "â”‚ 1         â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â”‚ 00:50:34  â”†           â”†           â”†           â”†   â”†           â”†           â”†           â”†          â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veri Ã¶nizleme\n",
    "print(\"\\nVeri Ã–rneÄŸi:\")\n",
    "df_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "âœ“ prepare_ml_data\n",
      "  SÃ¼re: 0.190 saniye\n",
      "  Bellek: 45.76 MB\n",
      "==================================================\n",
      "\n",
      "Train: (400000, 8)\n",
      "Test: (100000, 8)\n",
      "Features: ['trip_distance', 'pickup_hour', 'pickup_dayofweek', 'is_weekend', 'is_rush_hour', 'PULocationID', 'DOLocationID', 'passenger_count']\n"
     ]
    }
   ],
   "source": [
    "# ML iÃ§in sample al ve numpy'a Ã§evir\n",
    "# NOT: Pandas ile AYNI satÄ±rlarÄ± seÃ§mek iÃ§in NumPy random kullanÄ±yoruz\n",
    "def prepare_ml_data():\n",
    "    # 04 notebook ile AYNI yÃ¶ntem: NumPy ile index seÃ§\n",
    "    np.random.seed(42)  # Pandas ile aynÄ± seed\n",
    "    sample_size = min(500_000, len(df_features))\n",
    "    indices = np.random.choice(len(df_features), sample_size, replace=False)\n",
    "    \n",
    "    # Polars'ta iloc yerine gather kullan\n",
    "    df_sample = df_features[indices]\n",
    "    \n",
    "    # 04 notebook ile AYNI feature'lar\n",
    "    feature_cols = [\n",
    "        'trip_distance', 'pickup_hour', 'pickup_dayofweek',\n",
    "        'is_weekend', 'is_rush_hour', \n",
    "        'PULocationID', 'DOLocationID', 'passenger_count'\n",
    "    ]\n",
    "    \n",
    "    X = df_sample.select(feature_cols).to_numpy()\n",
    "    y = df_sample.select('fare_amount').to_numpy().ravel()\n",
    "    \n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42), feature_cols\n",
    "\n",
    "(X_train, X_test, y_train, y_test), feature_cols = benchmark(prepare_ml_data, 'prepare_ml_data')\n",
    "print(f\"\\nTrain: {X_train.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ray BaÅŸlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 08:30:51,531\tINFO worker.py:2023 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAY CLUSTER BÄ°LGÄ°SÄ°\n",
      "==================================================\n",
      "Nodes: 1\n",
      "CPUs: 12.0\n",
      "Memory: 58.1 GB\n"
     ]
    }
   ],
   "source": [
    "# Ray'i baÅŸlat\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "print(f\"\\nRAY CLUSTER BÄ°LGÄ°SÄ°\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Nodes: {len(ray.nodes())}\")\n",
    "print(f\"CPUs: {ray.cluster_resources().get('CPU', 0)}\")\n",
    "print(f\"Memory: {ray.cluster_resources().get('memory', 0) / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri Ray object store'a yÃ¼klendi\n"
     ]
    }
   ],
   "source": [
    "# Veriyi Ray object store'a yÃ¼kle\n",
    "X_train_ref = ray.put(X_train)\n",
    "y_train_ref = ray.put(y_train)\n",
    "X_test_ref = ray.put(X_test)\n",
    "y_test_ref = ray.put(y_test)\n",
    "\n",
    "print(\"Veri Ray object store'a yÃ¼klendi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ray ile Paralel Model KarÅŸÄ±laÅŸtÄ±rma\n",
    "\n",
    "FarklÄ± ML algoritmalarÄ±nÄ± paralel olarak eÄŸitip karÅŸÄ±laÅŸtÄ±racaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def train_and_evaluate(model_name, model_params, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Bir modeli eÄŸit ve deÄŸerlendir.\n",
    "    Ray remote olarak paralel Ã§alÄ±ÅŸÄ±r.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Model seÃ§imi\n",
    "    if model_name == 'RandomForest':\n",
    "        model = RandomForestRegressor(**model_params, random_state=42, n_jobs=1)\n",
    "    elif model_name == 'GradientBoosting':\n",
    "        model = GradientBoostingRegressor(**model_params, random_state=42)\n",
    "    elif model_name == 'XGBoost':\n",
    "        model = XGBRegressor(**model_params, random_state=42, n_jobs=1, verbosity=0)\n",
    "    elif model_name == 'Ridge':\n",
    "        model = Ridge(**model_params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    # EÄŸitim\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Tahmin\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Metrikler\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    duration = time.time() - start\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'params': model_params,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'duration': duration\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test edilecek model sayÄ±sÄ±: 14\n"
     ]
    }
   ],
   "source": [
    "# Model konfigÃ¼rasyonlarÄ± - 04 ile AYNI parametreler dahil\n",
    "model_configs = [\n",
    "    # Random Forest variants (04 ile aynÄ±)\n",
    "    ('RandomForest', {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 2}),\n",
    "    ('RandomForest', {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2}),\n",
    "    ('RandomForest', {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2}),\n",
    "    ('RandomForest', {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2}),\n",
    "    ('RandomForest', {'n_estimators': 100, 'max_depth': 15, 'min_samples_split': 5}),  \n",
    "    ('RandomForest', {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 2}),\n",
    "    ('RandomForest', {'n_estimators': 150, 'max_depth': 15, 'min_samples_split': 5}), \n",
    "    ('RandomForest', {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2}),\n",
    "    \n",
    "    # XGBoost variants\n",
    "    ('XGBoost', {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1}),\n",
    "    ('XGBoost', {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.1}),\n",
    "    ('XGBoost', {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05}),\n",
    "    \n",
    "    # Gradient Boosting variants  \n",
    "    ('GradientBoosting', {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.1}),\n",
    "    ('GradientBoosting', {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1}),\n",
    "    \n",
    "    # Ridge (baseline)\n",
    "    ('Ridge', {'alpha': 1.0}),\n",
    "]\n",
    "\n",
    "print(f\"Test edilecek model sayÄ±sÄ±: {len(model_configs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paralel model eÄŸitimi baÅŸlÄ±yor...\n",
      "14 model aynÄ± anda eÄŸitiliyor!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=gcs_server)\u001b[0m [2025-12-10 08:31:18,753 E 18750 18750] (gcs_server) gcs_server.cc:303: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[33m(raylet)\u001b[0m [2025-12-10 08:31:21,472 E 18865 18865] (raylet) main.cc:979: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(train_and_evaluate pid=18929)\u001b[0m [2025-12-10 08:31:24,852 E 18929 19039] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "âœ“ parallel_model_comparison\n",
      "  SÃ¼re: 176.807 saniye\n",
      "  Bellek: 0.84 MB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Paralel model eÄŸitimi\n",
    "def parallel_model_training():\n",
    "    futures = [\n",
    "        train_and_evaluate.remote(\n",
    "            model_name, params,\n",
    "            X_train_ref, y_train_ref,\n",
    "            X_test_ref, y_test_ref\n",
    "        )\n",
    "        for model_name, params in model_configs\n",
    "    ]\n",
    "    return ray.get(futures)\n",
    "\n",
    "print(\"Paralel model eÄŸitimi baÅŸlÄ±yor...\")\n",
    "print(f\"{len(model_configs)} model aynÄ± anda eÄŸitiliyor!\\n\")\n",
    "\n",
    "model_results = benchmark(parallel_model_training, 'parallel_model_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL KARÅILAÅTIRMA SONUÃ‡LARI\n",
      "==========================================================================================\n",
      "Model                Params                              RMSE ($)     MAE ($)      RÂ²         SÃ¼re (s)  \n",
      "------------------------------------------------------------------------------------------\n",
      "XGBoost              {'n_estimators': 150, 'max_depth'   3.57         1.66         0.9532     7.5       \n",
      "XGBoost              {'n_estimators': 200, 'max_depth'   3.60         1.69         0.9525     10.5      \n",
      "RandomForest         {'n_estimators': 150, 'max_depth'   3.62         1.71         0.9518     174.6     \n",
      "RandomForest         {'n_estimators': 100, 'max_depth'   3.62         1.71         0.9518     122.2     \n",
      "GradientBoosting     {'n_estimators': 100, 'max_depth'   3.63         1.74         0.9516     93.3      \n",
      "XGBoost              {'n_estimators': 100, 'max_depth'   3.68         1.75         0.9503     4.0       \n",
      "RandomForest         {'n_estimators': 200, 'max_depth'   3.69         1.80         0.9500     162.0     \n",
      "RandomForest         {'n_estimators': 150, 'max_depth'   3.69         1.80         0.9500     135.0     \n",
      "RandomForest         {'n_estimators': 100, 'max_depth'   3.69         1.80         0.9500     100.9     \n",
      "RandomForest         {'n_estimators': 50, 'max_depth':   3.69         1.80         0.9499     58.3      \n",
      "GradientBoosting     {'n_estimators': 50, 'max_depth':   3.69         1.80         0.9499     62.2      \n",
      "RandomForest         {'n_estimators': 100, 'max_depth'   4.04         2.08         0.9402     73.2      \n",
      "RandomForest         {'n_estimators': 50, 'max_depth':   4.04         2.08         0.9400     35.3      \n",
      "Ridge                {'alpha': 1.0}                      4.47         2.35         0.9267     0.1       \n",
      "\n",
      "==========================================================================================\n",
      "EN Ä°YÄ° MODEL: XGBoost\n",
      "Parametreler: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.1}\n",
      "RMSE: $3.57, RÂ²: 0.9532\n"
     ]
    }
   ],
   "source": [
    "# SonuÃ§larÄ± gÃ¶ster\n",
    "print(\"\\nMODEL KARÅILAÅTIRMA SONUÃ‡LARI\")\n",
    "print(\"=\"*90)\n",
    "print(f\"{'Model':<20} {'Params':<35} {'RMSE ($)':<12} {'MAE ($)':<12} {'RÂ²':<10} {'SÃ¼re (s)':<10}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "sorted_results = sorted(model_results, key=lambda x: x['rmse'])\n",
    "for r in sorted_results:\n",
    "    params_str = str(r['params'])[:33]\n",
    "    print(f\"{r['model']:<20} {params_str:<35} {r['rmse']:<12.2f} {r['mae']:<12.2f} {r['r2']:<10.4f} {r['duration']:<10.1f}\")\n",
    "\n",
    "best_model = sorted_results[0]\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"EN Ä°YÄ° MODEL: {best_model['model']}\")\n",
    "print(f\"Parametreler: {best_model['params']}\")\n",
    "print(f\"RMSE: ${best_model['rmse']:.2f}, RÂ²: {best_model['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ray ile Hyperparameter Tuning (En Ä°yi Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost iÃ§in 36 parametre kombinasyonu test edilecek\n"
     ]
    }
   ],
   "source": [
    "# En iyi model tipi iÃ§in detaylÄ± hyperparameter search\n",
    "best_model_type = best_model['model']\n",
    "\n",
    "if best_model_type == 'XGBoost':\n",
    "    tuning_configs = [\n",
    "        {'n_estimators': n, 'max_depth': d, 'learning_rate': lr, 'subsample': ss}\n",
    "        for n in [100, 150, 200]\n",
    "        for d in [5, 7, 9]\n",
    "        for lr in [0.05, 0.1]\n",
    "        for ss in [0.8, 1.0]\n",
    "    ]\n",
    "elif best_model_type == 'RandomForest':\n",
    "    tuning_configs = [\n",
    "        {'n_estimators': n, 'max_depth': d, 'min_samples_split': ms}\n",
    "        for n in [100, 150, 200]\n",
    "        for d in [10, 15, 20]\n",
    "        for ms in [2, 5, 10]\n",
    "    ]\n",
    "else:\n",
    "    tuning_configs = [\n",
    "        {'n_estimators': n, 'max_depth': d, 'learning_rate': lr}\n",
    "        for n in [50, 100, 150]\n",
    "        for d in [3, 5, 7]\n",
    "        for lr in [0.05, 0.1, 0.2]\n",
    "    ]\n",
    "\n",
    "print(f\"\\n{best_model_type} iÃ§in {len(tuning_configs)} parametre kombinasyonu test edilecek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paralel hyperparameter tuning baÅŸlÄ±yor...\n",
      "\n",
      "==================================================\n",
      "âœ“ hyperparameter_tuning\n",
      "  SÃ¼re: 28.662 saniye\n",
      "  Bellek: 0.57 MB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# DetaylÄ± hyperparameter tuning\n",
    "def detailed_hyperparameter_tuning():\n",
    "    futures = [\n",
    "        train_and_evaluate.remote(\n",
    "            best_model_type, params,\n",
    "            X_train_ref, y_train_ref,\n",
    "            X_test_ref, y_test_ref\n",
    "        )\n",
    "        for params in tuning_configs\n",
    "    ]\n",
    "    return ray.get(futures)\n",
    "\n",
    "print(f\"Paralel hyperparameter tuning baÅŸlÄ±yor...\")\n",
    "tuning_results = benchmark(detailed_hyperparameter_tuning, 'hyperparameter_tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost - EN Ä°YÄ° 10 PARAMETRE KOMBÄ°NASYONU\n",
      "================================================================================\n",
      "1. RMSE: $3.566, RÂ²: 0.9533\n",
      "   Params: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 1.0}\n",
      "2. RMSE: $3.567, RÂ²: 0.9532\n",
      "   Params: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.1, 'subsample': 1.0}\n",
      "3. RMSE: $3.570, RÂ²: 0.9532\n",
      "   Params: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.1, 'subsample': 1.0}\n",
      "4. RMSE: $3.574, RÂ²: 0.9531\n",
      "   Params: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.1, 'subsample': 1.0}\n",
      "5. RMSE: $3.578, RÂ²: 0.9530\n",
      "   Params: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.1, 'subsample': 1.0}\n",
      "6. RMSE: $3.580, RÂ²: 0.9529\n",
      "   Params: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.1, 'subsample': 1.0}\n",
      "7. RMSE: $3.581, RÂ²: 0.9529\n",
      "   Params: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 1.0}\n",
      "8. RMSE: $3.596, RÂ²: 0.9525\n",
      "   Params: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.05, 'subsample': 1.0}\n",
      "9. RMSE: $3.596, RÂ²: 0.9525\n",
      "   Params: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.1, 'subsample': 1.0}\n",
      "10. RMSE: $3.597, RÂ²: 0.9525\n",
      "   Params: {'n_estimators': 150, 'max_depth': 9, 'learning_rate': 0.05, 'subsample': 0.8}\n",
      "\n",
      "================================================================================\n",
      "FÄ°NAL EN Ä°YÄ°: RMSE=$3.566, RÂ²=0.9533\n"
     ]
    }
   ],
   "source": [
    "# En iyi sonuÃ§larÄ± gÃ¶ster\n",
    "sorted_tuning = sorted(tuning_results, key=lambda x: x['rmse'])[:10]\n",
    "\n",
    "print(f\"\\n{best_model_type} - EN Ä°YÄ° 10 PARAMETRE KOMBÄ°NASYONU\")\n",
    "print(\"=\"*80)\n",
    "for i, r in enumerate(sorted_tuning, 1):\n",
    "    print(f\"{i}. RMSE: ${r['rmse']:.3f}, RÂ²: {r['r2']:.4f}\")\n",
    "    print(f\"   Params: {r['params']}\")\n",
    "\n",
    "final_best = sorted_tuning[0]\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FÄ°NAL EN Ä°YÄ°: RMSE=${final_best['rmse']:.3f}, RÂ²={final_best['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Polars ile HÄ±zlÄ± Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model eÄŸitildi: XGBoost\n"
     ]
    }
   ],
   "source": [
    "# Final modeli eÄŸit\n",
    "if best_model_type == 'XGBoost':\n",
    "    final_model = XGBRegressor(**final_best['params'], random_state=42, n_jobs=-1, verbosity=0)\n",
    "elif best_model_type == 'RandomForest':\n",
    "    final_model = RandomForestRegressor(**final_best['params'], random_state=42, n_jobs=-1)\n",
    "else:\n",
    "    final_model = GradientBoostingRegressor(**final_best['params'], random_state=42)\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "print(f\"Final model eÄŸitildi: {best_model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "âœ“ batch_prediction\n",
      "  SÃ¼re: 0.274 saniye\n",
      "  Bellek: 1.10 MB\n",
      "==================================================\n",
      "\n",
      "Tahmin yapÄ±lan satÄ±r: 100,000\n"
     ]
    }
   ],
   "source": [
    "# Polars ile yeni veri iÃ§in batch prediction\n",
    "def polars_batch_prediction():\n",
    "    # AynÄ± ayÄ±n verisinden farklÄ± sample al\n",
    "    new_data = (\n",
    "        pl.scan_parquet(taxi_files[0])  # Ocak 2023\n",
    "        .select([\n",
    "            'tpep_pickup_datetime',\n",
    "            'trip_distance',\n",
    "            'PULocationID',\n",
    "            'DOLocationID',\n",
    "            'passenger_count',\n",
    "            'fare_amount'\n",
    "        ])\n",
    "        .filter(\n",
    "            (pl.col('fare_amount') > 0) &\n",
    "            (pl.col('trip_distance') > 0) &\n",
    "            (pl.col('passenger_count') > 0) &\n",
    "            (pl.col('passenger_count').is_not_null())\n",
    "        )\n",
    "        .with_columns([\n",
    "            pl.col('tpep_pickup_datetime').dt.hour().alias('pickup_hour'),\n",
    "            pl.col('tpep_pickup_datetime').dt.weekday().alias('pickup_dayofweek'),\n",
    "            (pl.col('tpep_pickup_datetime').dt.weekday() >= 5).cast(pl.Int8).alias('is_weekend'),\n",
    "            (\n",
    "                ((pl.col('tpep_pickup_datetime').dt.hour() >= 7) & \n",
    "                 (pl.col('tpep_pickup_datetime').dt.hour() <= 9)) |\n",
    "                ((pl.col('tpep_pickup_datetime').dt.hour() >= 17) & \n",
    "                 (pl.col('tpep_pickup_datetime').dt.hour() <= 19))\n",
    "            ).cast(pl.Int8).alias('is_rush_hour'),\n",
    "        ])\n",
    "        .head(100_000)  # Ä°lk 100K\n",
    "        .collect()\n",
    "    )\n",
    "    \n",
    "    # Feature matrix\n",
    "    X_new = new_data.select(feature_cols).to_numpy()\n",
    "    \n",
    "    # Tahmin\n",
    "    predictions = final_model.predict(X_new)\n",
    "    \n",
    "    # SonuÃ§larÄ± Polars DataFrame'e ekle\n",
    "    result = new_data.with_columns([\n",
    "        pl.Series('predicted_fare', predictions)\n",
    "    ]).with_columns([\n",
    "        (pl.col('fare_amount') - pl.col('predicted_fare')).alias('prediction_error')\n",
    "    ])\n",
    "    \n",
    "    return result\n",
    "\n",
    "predictions_df = benchmark(polars_batch_prediction, 'batch_prediction')\n",
    "print(f\"\\nTahmin yapÄ±lan satÄ±r: {len(predictions_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAHMÄ°N SONUÃ‡LARI Ã–RNEÄÄ°\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>trip_distance</th><th>pickup_hour</th><th>fare_amount</th><th>predicted_fare</th><th>prediction_error</th></tr><tr><td>f64</td><td>i8</td><td>f64</td><td>f32</td><td>f64</td></tr></thead><tbody><tr><td>0.97</td><td>0</td><td>9.3</td><td>8.063667</td><td>1.236333</td></tr><tr><td>1.1</td><td>0</td><td>7.9</td><td>7.989832</td><td>-0.089832</td></tr><tr><td>2.51</td><td>0</td><td>14.9</td><td>14.37742</td><td>0.52258</td></tr><tr><td>1.43</td><td>0</td><td>11.4</td><td>10.483186</td><td>0.916814</td></tr><tr><td>1.84</td><td>0</td><td>12.8</td><td>12.477262</td><td>0.322738</td></tr><tr><td>1.66</td><td>0</td><td>12.1</td><td>10.862745</td><td>1.237255</td></tr><tr><td>11.7</td><td>0</td><td>45.7</td><td>46.646633</td><td>-0.946633</td></tr><tr><td>2.95</td><td>0</td><td>17.7</td><td>16.641829</td><td>1.058171</td></tr><tr><td>3.01</td><td>0</td><td>14.9</td><td>16.49785</td><td>-1.59785</td></tr><tr><td>1.8</td><td>0</td><td>11.4</td><td>12.153728</td><td>-0.753728</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 5)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ trip_distance â”† pickup_hour â”† fare_amount â”† predicted_fare â”† prediction_error â”‚\n",
       "â”‚ ---           â”† ---         â”† ---         â”† ---            â”† ---              â”‚\n",
       "â”‚ f64           â”† i8          â”† f64         â”† f32            â”† f64              â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0.97          â”† 0           â”† 9.3         â”† 8.063667       â”† 1.236333         â”‚\n",
       "â”‚ 1.1           â”† 0           â”† 7.9         â”† 7.989832       â”† -0.089832        â”‚\n",
       "â”‚ 2.51          â”† 0           â”† 14.9        â”† 14.37742       â”† 0.52258          â”‚\n",
       "â”‚ 1.43          â”† 0           â”† 11.4        â”† 10.483186      â”† 0.916814         â”‚\n",
       "â”‚ 1.84          â”† 0           â”† 12.8        â”† 12.477262      â”† 0.322738         â”‚\n",
       "â”‚ 1.66          â”† 0           â”† 12.1        â”† 10.862745      â”† 1.237255         â”‚\n",
       "â”‚ 11.7          â”† 0           â”† 45.7        â”† 46.646633      â”† -0.946633        â”‚\n",
       "â”‚ 2.95          â”† 0           â”† 17.7        â”† 16.641829      â”† 1.058171         â”‚\n",
       "â”‚ 3.01          â”† 0           â”† 14.9        â”† 16.49785       â”† -1.59785         â”‚\n",
       "â”‚ 1.8           â”† 0           â”† 11.4        â”† 12.153728      â”† -0.753728        â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tahmin sonuÃ§larÄ±\n",
    "print(\"\\nTAHMÄ°N SONUÃ‡LARI Ã–RNEÄÄ°\")\n",
    "print(\"=\"*80)\n",
    "predictions_df.select([\n",
    "    'trip_distance', 'pickup_hour', 'fare_amount', \n",
    "    'predicted_fare', 'prediction_error'\n",
    "]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BATCH PREDICTION Ä°STATÄ°STÄ°KLERÄ°\n",
      "shape: (1, 4)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ MAE      â”† Median_AE â”† RMSE     â”† Mean_Error â”‚\n",
      "â”‚ ---      â”† ---       â”† ---      â”† ---        â”‚\n",
      "â”‚ f64      â”† f64       â”† f64      â”† f64        â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2.100425 â”† 1.141557  â”† 5.521032 â”† 0.018744   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# Prediction istatistikleri\n",
    "pred_stats = predictions_df.select([\n",
    "    pl.col('prediction_error').abs().mean().alias('MAE'),\n",
    "    pl.col('prediction_error').abs().median().alias('Median_AE'),\n",
    "    (pl.col('prediction_error')**2).mean().sqrt().alias('RMSE'),\n",
    "    pl.col('prediction_error').mean().alias('Mean_Error'),\n",
    "])\n",
    "\n",
    "print(\"\\nBATCH PREDICTION Ä°STATÄ°STÄ°KLERÄ°\")\n",
    "print(pred_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performans Ã–zeti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SonuÃ§lar kaydedildi: results/polars_ray_benchmark.json\n"
     ]
    }
   ],
   "source": [
    "# SonuÃ§larÄ± kaydet\n",
    "results['total_memory_mb'] = round(get_memory_mb(), 2)\n",
    "results['total_memory_gb'] = round(get_memory_mb() / 1024, 2)\n",
    "results['row_count'] = int(total_rows)\n",
    "results['best_model'] = best_model_type\n",
    "results['best_params'] = final_best['params']\n",
    "results['best_rmse'] = round(final_best['rmse'], 3)\n",
    "results['best_r2'] = round(final_best['r2'], 4)\n",
    "results['models_tested'] = len(model_configs) + len(tuning_configs)\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "with open('results/polars_ray_benchmark.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"SonuÃ§lar kaydedildi: results/polars_ray_benchmark.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "POLARS + RAY HÄ°BRÄ°T PÄ°PELÄ°NE Ã–ZET\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š VERÄ°\n",
      "   Toplam satÄ±r: 3,066,766\n",
      "   Dosya boyutu: 606.3 MB\n",
      "\n",
      "âš¡ POLARS PERFORMANSI\n",
      "   polars_lazy_scan: 0.00s\n",
      "   polars_aggregations: 0.15s\n",
      "   polars_feature_engineering: 0.15s\n",
      "\n",
      "ğŸš€ RAY PERFORMANSI\n",
      "   parallel_model_comparison: 178.09s\n",
      "   hyperparameter_tuning: 28.44s\n",
      "\n",
      "ğŸ† EN Ä°YÄ° MODEL\n",
      "   Algoritma: XGBoost\n",
      "   RMSE: $3.76\n",
      "   RÂ²: 0.9479\n",
      "   Parametreler: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.1, 'subsample': 1.0}\n",
      "\n",
      "ğŸ“ˆ TOPLAM\n",
      "   Toplam sÃ¼re: 207.2s\n",
      "   Test edilen model: 50\n",
      "   Bellek kullanÄ±mÄ±: 6.15 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"POLARS + RAY HÄ°BRÄ°T PÄ°PELÄ°NE Ã–ZET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nğŸ“Š VERÄ°\")\n",
    "print(f\"   Toplam satÄ±r: {total_rows:,}\")\n",
    "print(f\"   Dosya boyutu: {total_size / 1024**2:.1f} MB\")\n",
    "\n",
    "print(\"\\nâš¡ POLARS PERFORMANSI\")\n",
    "polars_ops = ['polars_lazy_scan', 'polars_aggregations', 'polars_feature_engineering']\n",
    "for op in polars_ops:\n",
    "    if op in results['operations']:\n",
    "        print(f\"   {op}: {results['operations'][op]['duration_sec']:.2f}s\")\n",
    "\n",
    "print(\"\\nğŸš€ RAY PERFORMANSI\")\n",
    "ray_ops = ['parallel_model_comparison', 'hyperparameter_tuning']\n",
    "for op in ray_ops:\n",
    "    if op in results['operations']:\n",
    "        print(f\"   {op}: {results['operations'][op]['duration_sec']:.2f}s\")\n",
    "\n",
    "print(\"\\nğŸ† EN Ä°YÄ° MODEL\")\n",
    "print(f\"   Algoritma: {best_model_type}\")\n",
    "print(f\"   RMSE: ${final_best['rmse']:.2f}\")\n",
    "print(f\"   RÂ²: {final_best['r2']:.4f}\")\n",
    "print(f\"   Parametreler: {final_best['params']}\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ TOPLAM\")\n",
    "total_time = sum(op['duration_sec'] for op in results['operations'].values())\n",
    "print(f\"   Toplam sÃ¼re: {total_time:.1f}s\")\n",
    "print(f\"   Test edilen model: {results['models_tested']}\")\n",
    "print(f\"   Bellek kullanÄ±mÄ±: {results['total_memory_gb']:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                    POLARS + RAY KOMBÄ°NASYONU                         â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘                                                                      â•‘\n",
      "â•‘  POLARS (Veri Ä°ÅŸleme)                                               â•‘\n",
      "â•‘  â”œâ”€ Lazy evaluation â†’ Sadece gerekli veri okunur                   â•‘\n",
      "â•‘  â”œâ”€ Predicate pushdown â†’ Filtreler dosya seviyesinde               â•‘\n",
      "â•‘  â”œâ”€ Column projection â†’ Sadece gerekli sÃ¼tunlar                    â•‘\n",
      "â•‘  â””â”€ Paralel execution â†’ TÃ¼m CPU'lar kullanÄ±lÄ±r                     â•‘\n",
      "â•‘                                                                      â•‘\n",
      "â•‘  RAY (ML Pipeline)                                                  â•‘\n",
      "â•‘  â”œâ”€ @ray.remote â†’ FonksiyonlarÄ± paralel Ã§alÄ±ÅŸtÄ±r                   â•‘\n",
      "â•‘  â”œâ”€ Object store â†’ Zero-copy veri paylaÅŸÄ±mÄ±                        â•‘\n",
      "â•‘  â”œâ”€ Task scheduling â†’ Otomatik iÅŸ daÄŸÄ±lÄ±mÄ±                         â•‘\n",
      "â•‘  â””â”€ Scalability â†’ Cluster'a kolayca scale                          â•‘\n",
      "â•‘                                                                      â•‘\n",
      "â•‘  BÄ°RLÄ°KTE                                                           â•‘\n",
      "â•‘  â”œâ”€ Polars: Veri yÃ¼kle, temizle, feature engineering               â•‘\n",
      "â•‘  â”œâ”€ NumPy: ML kÃ¼tÃ¼phaneleri iÃ§in dÃ¶nÃ¼ÅŸÃ¼m                          â•‘\n",
      "â•‘  â”œâ”€ Ray: Model eÄŸitimi ve hyperparameter tuning                    â•‘\n",
      "â•‘  â””â”€ Polars: Batch prediction ve sonuÃ§ analizi                      â•‘\n",
      "â•‘                                                                      â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    POLARS + RAY KOMBÄ°NASYONU                         â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                      â•‘\n",
    "â•‘  POLARS (Veri Ä°ÅŸleme)                                               â•‘\n",
    "â•‘  â”œâ”€ Lazy evaluation â†’ Sadece gerekli veri okunur                   â•‘\n",
    "â•‘  â”œâ”€ Predicate pushdown â†’ Filtreler dosya seviyesinde               â•‘\n",
    "â•‘  â”œâ”€ Column projection â†’ Sadece gerekli sÃ¼tunlar                    â•‘\n",
    "â•‘  â””â”€ Paralel execution â†’ TÃ¼m CPU'lar kullanÄ±lÄ±r                     â•‘\n",
    "â•‘                                                                      â•‘\n",
    "â•‘  RAY (ML Pipeline)                                                  â•‘\n",
    "â•‘  â”œâ”€ @ray.remote â†’ FonksiyonlarÄ± paralel Ã§alÄ±ÅŸtÄ±r                   â•‘\n",
    "â•‘  â”œâ”€ Object store â†’ Zero-copy veri paylaÅŸÄ±mÄ±                        â•‘\n",
    "â•‘  â”œâ”€ Task scheduling â†’ Otomatik iÅŸ daÄŸÄ±lÄ±mÄ±                         â•‘\n",
    "â•‘  â””â”€ Scalability â†’ Cluster'a kolayca scale                          â•‘\n",
    "â•‘                                                                      â•‘\n",
    "â•‘  BÄ°RLÄ°KTE                                                           â•‘\n",
    "â•‘  â”œâ”€ Polars: Veri yÃ¼kle, temizle, feature engineering               â•‘\n",
    "â•‘  â”œâ”€ NumPy: ML kÃ¼tÃ¼phaneleri iÃ§in dÃ¶nÃ¼ÅŸÃ¼m                          â•‘\n",
    "â•‘  â”œâ”€ Ray: Model eÄŸitimi ve hyperparameter tuning                    â•‘\n",
    "â•‘  â””â”€ Polars: Batch prediction ve sonuÃ§ analizi                      â•‘\n",
    "â•‘                                                                      â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray kapatÄ±ldÄ±.\n"
     ]
    }
   ],
   "source": [
    "# Ray'i kapat\n",
    "ray.shutdown()\n",
    "print(\"Ray kapatÄ±ldÄ±.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## SonuÃ§\n",
    "\n",
    "Bu notebook'ta **Polars + Ray** kombinasyonunun gÃ¼cÃ¼nÃ¼ gÃ¶rdÃ¼k:\n",
    "\n",
    "| BileÅŸen | GÃ¶rev | Avantaj |\n",
    "|---------|-------|--------|\n",
    "| **Polars** | Veri yÃ¼kleme | Lazy evaluation, predicate pushdown |\n",
    "| **Polars** | Feature engineering | Expression API, paralel execution |\n",
    "| **Ray** | Model training | @ray.remote ile paralellestirme |\n",
    "| **Ray** | Hyperparameter tuning | TÃ¼m kombinasyonlar aynÄ± anda |\n",
    "| **Polars** | Batch prediction | HÄ±zlÄ± tahmin ve analiz |\n",
    "\n",
    "**GerÃ§ek dÃ¼nya senaryolarÄ±nda bu kombinasyon:**\n",
    "- BÃ¼yÃ¼k veri setlerinde bellek tasarrufu\n",
    "- Model geliÅŸtirme sÃ¼resini kÄ±saltma\n",
    "- Production-ready pipeline oluÅŸturma\n",
    "\n",
    "iÃ§in idealdir!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
