{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Ray: Distributed ML Pipeline\n",
    "\n",
    "Bu notebook'ta Ray ile distributed ML pipeline olusturacagiz.\n",
    "\n",
    "**Ray Ozellikleri:**\n",
    "- @ray.remote ile kolay paralellestirme\n",
    "- Ray Train: Distributed model training\n",
    "- Ray Tune: Hyperparameter optimization\n",
    "- Ray Data: Large-scale data processing\n",
    "\n",
    "**Kullanim Alani:** NYC Taxi ucret tahmini (Fare Prediction)\n",
    "\n",
    "**Veri Seti:** NYC Yellow Taxi 2023 (12 ay, ~40M satir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kurulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m155.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Ray ve ML kutuphaneleri kurulumu\n",
    "!pip install \"ray[default]\" scikit-learn xgboost pyarrow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray version: 2.52.0\n",
      "CPU count: 12\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "import urllib.request\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "print(f\"Ray version: {ray.__version__}\")\n",
    "print(f\"CPU count: {os.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark fonksiyonlari\n",
    "results = {\n",
    "    'framework': 'ray',\n",
    "    'dataset': 'nyc_taxi_12_months',\n",
    "    'operations': {}\n",
    "}\n",
    "\n",
    "def get_memory_mb():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "def benchmark(func, name):\n",
    "    gc.collect()\n",
    "    mem_before = get_memory_mb()\n",
    "    start = time.time()\n",
    "    result = func()\n",
    "    end = time.time()\n",
    "    mem_after = get_memory_mb()\n",
    "    \n",
    "    duration = end - start\n",
    "    mem_used = mem_after - mem_before\n",
    "    \n",
    "    results['operations'][name] = {\n",
    "        'duration_sec': round(duration, 3),\n",
    "        'memory_mb': round(mem_used, 2)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Operation: {name}\")\n",
    "    print(f\"Sure: {duration:.3f} saniye\")\n",
    "    print(f\"Bellek: {mem_used:.2f} MB\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mevcut: yellow_tripdata_2023-01.parquet\n",
      "Mevcut: yellow_tripdata_2023-02.parquet\n",
      "Mevcut: yellow_tripdata_2023-03.parquet\n",
      "Mevcut: yellow_tripdata_2023-04.parquet\n",
      "Mevcut: yellow_tripdata_2023-05.parquet\n",
      "Mevcut: yellow_tripdata_2023-06.parquet\n",
      "Mevcut: yellow_tripdata_2023-07.parquet\n",
      "Mevcut: yellow_tripdata_2023-08.parquet\n",
      "Mevcut: yellow_tripdata_2023-09.parquet\n",
      "Mevcut: yellow_tripdata_2023-10.parquet\n",
      "Mevcut: yellow_tripdata_2023-11.parquet\n",
      "Mevcut: yellow_tripdata_2023-12.parquet\n",
      "\n",
      "Toplam dosya boyutu: 606.3 MB\n",
      "Dosya sayisi: 12\n"
     ]
    }
   ],
   "source": [
    "# Veri indirme - 12 ay\n",
    "DATA_DIR = 'data'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "MONTHS = ['2023-01', '2023-02', '2023-03', '2023-04', '2023-05', '2023-06',\n",
    "          '2023-07', '2023-08', '2023-09', '2023-10', '2023-11', '2023-12']\n",
    "BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{}.parquet\"\n",
    "\n",
    "taxi_files = []\n",
    "total_size = 0\n",
    "\n",
    "for month in MONTHS:\n",
    "    filename = f\"yellow_tripdata_{month}.parquet\"\n",
    "    filepath = os.path.join(DATA_DIR, filename)\n",
    "    taxi_files.append(filepath)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        url = BASE_URL.format(month)\n",
    "        print(f\"Indiriliyor: {filename}...\")\n",
    "        urllib.request.urlretrieve(url, filepath)\n",
    "        print(f\"Indirildi: {filename}\")\n",
    "    else:\n",
    "        print(f\"Mevcut: {filename}\")\n",
    "    \n",
    "    total_size += os.path.getsize(filepath)\n",
    "\n",
    "print(f\"\\nToplam dosya boyutu: {total_size / 1024**2:.1f} MB\")\n",
    "print(f\"Dosya sayisi: {len(taxi_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ray Baslat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 00:41:43,449\tINFO worker.py:2014 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAY CLUSTER BILGISI\n",
      "==================================================\n",
      "Nodes: 1\n",
      "CPUs: 12.0\n",
      "Memory: 58.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Ray'i baslat\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "print(f\"\\nRAY CLUSTER BILGISI\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Nodes: {len(ray.nodes())}\")\n",
    "print(f\"CPUs: {ray.cluster_resources().get('CPU', 0)}\")\n",
    "print(f\"Memory: {ray.cluster_resources().get('memory', 0) / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. @ray.remote ile Paralel Veri Yukleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ray remote fonksiyonu - paralel dosya yukleme ve istatistik\n",
    "@ray.remote\n",
    "def load_and_process_file(file_path):\n",
    "    \"\"\"Tek bir dosyayi yukle ve isle\"\"\"\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Temel istatistikler\n",
    "    stats = {\n",
    "        'file': os.path.basename(file_path),\n",
    "        'rows': len(df),\n",
    "        'avg_fare': df['fare_amount'].mean(),\n",
    "        'avg_distance': df['trip_distance'].mean(),\n",
    "        'avg_tip': df['tip_amount'].mean(),\n",
    "        'total_revenue': df['total_amount'].sum()\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Operation: parallel_file_stats\n",
      "Sure: 3.146 saniye\n",
      "Bellek: 6.22 MB\n",
      "==================================================\n",
      "\n",
      "Aylik Istatistikler (Paralel Yukleme):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0752a7d6-001d-42f5-b723-dcb1a4c548b0\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>rows</th>\n",
       "      <th>avg_fare</th>\n",
       "      <th>avg_distance</th>\n",
       "      <th>avg_tip</th>\n",
       "      <th>total_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yellow_tripdata_2023-01.parquet</td>\n",
       "      <td>3066766</td>\n",
       "      <td>18.367069</td>\n",
       "      <td>3.847342</td>\n",
       "      <td>3.367941</td>\n",
       "      <td>8.286519e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yellow_tripdata_2023-02.parquet</td>\n",
       "      <td>2913955</td>\n",
       "      <td>18.220381</td>\n",
       "      <td>3.868058</td>\n",
       "      <td>3.384825</td>\n",
       "      <td>7.838097e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yellow_tripdata_2023-03.parquet</td>\n",
       "      <td>3403766</td>\n",
       "      <td>18.908448</td>\n",
       "      <td>3.903871</td>\n",
       "      <td>3.495237</td>\n",
       "      <td>9.463636e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yellow_tripdata_2023-04.parquet</td>\n",
       "      <td>3288250</td>\n",
       "      <td>19.360578</td>\n",
       "      <td>4.096176</td>\n",
       "      <td>3.512068</td>\n",
       "      <td>9.295724e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yellow_tripdata_2023-05.parquet</td>\n",
       "      <td>3513649</td>\n",
       "      <td>19.876871</td>\n",
       "      <td>4.345816</td>\n",
       "      <td>3.609887</td>\n",
       "      <td>1.017658e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yellow_tripdata_2023-06.parquet</td>\n",
       "      <td>3307234</td>\n",
       "      <td>19.988040</td>\n",
       "      <td>4.368790</td>\n",
       "      <td>3.594915</td>\n",
       "      <td>9.613708e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yellow_tripdata_2023-07.parquet</td>\n",
       "      <td>2907108</td>\n",
       "      <td>19.703195</td>\n",
       "      <td>4.489381</td>\n",
       "      <td>3.446826</td>\n",
       "      <td>8.304982e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yellow_tripdata_2023-08.parquet</td>\n",
       "      <td>2824209</td>\n",
       "      <td>19.718527</td>\n",
       "      <td>4.782808</td>\n",
       "      <td>3.410652</td>\n",
       "      <td>8.085198e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yellow_tripdata_2023-09.parquet</td>\n",
       "      <td>2846722</td>\n",
       "      <td>20.671109</td>\n",
       "      <td>4.274268</td>\n",
       "      <td>3.625289</td>\n",
       "      <td>8.478090e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yellow_tripdata_2023-10.parquet</td>\n",
       "      <td>3522285</td>\n",
       "      <td>20.061740</td>\n",
       "      <td>3.926695</td>\n",
       "      <td>3.632724</td>\n",
       "      <td>1.027499e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yellow_tripdata_2023-11.parquet</td>\n",
       "      <td>3339715</td>\n",
       "      <td>19.651354</td>\n",
       "      <td>3.632742</td>\n",
       "      <td>3.618372</td>\n",
       "      <td>9.583568e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yellow_tripdata_2023-12.parquet</td>\n",
       "      <td>3376567</td>\n",
       "      <td>19.666897</td>\n",
       "      <td>3.676258</td>\n",
       "      <td>3.517045</td>\n",
       "      <td>9.637256e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0752a7d6-001d-42f5-b723-dcb1a4c548b0')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0752a7d6-001d-42f5-b723-dcb1a4c548b0 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0752a7d6-001d-42f5-b723-dcb1a4c548b0');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                               file     rows   avg_fare  avg_distance  \\\n",
       "0   yellow_tripdata_2023-01.parquet  3066766  18.367069      3.847342   \n",
       "1   yellow_tripdata_2023-02.parquet  2913955  18.220381      3.868058   \n",
       "2   yellow_tripdata_2023-03.parquet  3403766  18.908448      3.903871   \n",
       "3   yellow_tripdata_2023-04.parquet  3288250  19.360578      4.096176   \n",
       "4   yellow_tripdata_2023-05.parquet  3513649  19.876871      4.345816   \n",
       "5   yellow_tripdata_2023-06.parquet  3307234  19.988040      4.368790   \n",
       "6   yellow_tripdata_2023-07.parquet  2907108  19.703195      4.489381   \n",
       "7   yellow_tripdata_2023-08.parquet  2824209  19.718527      4.782808   \n",
       "8   yellow_tripdata_2023-09.parquet  2846722  20.671109      4.274268   \n",
       "9   yellow_tripdata_2023-10.parquet  3522285  20.061740      3.926695   \n",
       "10  yellow_tripdata_2023-11.parquet  3339715  19.651354      3.632742   \n",
       "11  yellow_tripdata_2023-12.parquet  3376567  19.666897      3.676258   \n",
       "\n",
       "     avg_tip  total_revenue  \n",
       "0   3.367941   8.286519e+07  \n",
       "1   3.384825   7.838097e+07  \n",
       "2   3.495237   9.463636e+07  \n",
       "3   3.512068   9.295724e+07  \n",
       "4   3.609887   1.017658e+08  \n",
       "5   3.594915   9.613708e+07  \n",
       "6   3.446826   8.304982e+07  \n",
       "7   3.410652   8.085198e+07  \n",
       "8   3.625289   8.478090e+07  \n",
       "9   3.632724   1.027499e+08  \n",
       "10  3.618372   9.583568e+07  \n",
       "11  3.517045   9.637256e+07  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paralel istatistik hesapla\n",
    "def parallel_stats():\n",
    "    # Tum dosyalari paralel isle\n",
    "    futures = [load_and_process_file.remote(f) for f in taxi_files]\n",
    "    results_list = ray.get(futures)\n",
    "    return pd.DataFrame(results_list)\n",
    "\n",
    "df_stats = benchmark(parallel_stats, 'parallel_file_stats')\n",
    "print(\"\\nAylik Istatistikler (Paralel Yukleme):\")\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Toplam satir: 38,310,226\n",
      "Toplam gelir: $1,090,383,412\n"
     ]
    }
   ],
   "source": [
    "# Toplam satir sayisi\n",
    "total_rows = df_stats['rows'].sum()\n",
    "print(f\"\\nToplam satir: {total_rows:,}\")\n",
    "print(f\"Toplam gelir: ${df_stats['total_revenue'].sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ML icin Veri Hazirlama\n",
    "\n",
    "Bellek tasarrufu icin 1 aylik veri ile model egitecegiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Operation: load_sample_data\n",
      "Sure: 0.316 saniye\n",
      "Bellek: 566.91 MB\n",
      "==================================================\n",
      "\n",
      "Sample veri: 3,066,766 satir\n"
     ]
    }
   ],
   "source": [
    "# 1 aylik veri yukle (ML icin yeterli)\n",
    "def load_sample_data():\n",
    "    df = pd.read_parquet(taxi_files[0])  # Ocak 2023\n",
    "    return df\n",
    "\n",
    "df_sample = benchmark(load_sample_data, 'load_sample_data')\n",
    "print(f\"\\nSample veri: {len(df_sample):,} satir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Operation: feature_engineering\n",
      "Sure: 2.979 saniye\n",
      "Bellek: 740.66 MB\n",
      "==================================================\n",
      "\n",
      "Feature shape: (2883426, 8)\n",
      "Features: ['trip_distance', 'pickup_hour', 'pickup_dayofweek', 'is_weekend', 'is_rush_hour', 'PULocationID', 'DOLocationID', 'passenger_count']\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "def prepare_features():\n",
    "    df = df_sample.copy()\n",
    "    \n",
    "    # Datetime features\n",
    "    df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "    df['pickup_dayofweek'] = df['tpep_pickup_datetime'].dt.dayofweek\n",
    "    df['pickup_day'] = df['tpep_pickup_datetime'].dt.day\n",
    "    \n",
    "    # Is weekend?\n",
    "    df['is_weekend'] = (df['pickup_dayofweek'] >= 5).astype(int)\n",
    "    \n",
    "    # Rush hour? (7-9, 17-19)\n",
    "    df['is_rush_hour'] = df['pickup_hour'].apply(\n",
    "        lambda x: 1 if (7 <= x <= 9) or (17 <= x <= 19) else 0\n",
    "    )\n",
    "    \n",
    "    # Feature selection\n",
    "    feature_cols = [\n",
    "        'trip_distance', 'pickup_hour', 'pickup_dayofweek', \n",
    "        'is_weekend', 'is_rush_hour', 'PULocationID', 'DOLocationID',\n",
    "        'passenger_count'\n",
    "    ]\n",
    "    \n",
    "    # Target\n",
    "    target_col = 'fare_amount'\n",
    "    \n",
    "    # Temizlik\n",
    "    df = df.dropna(subset=feature_cols + [target_col])\n",
    "    df = df[(df['fare_amount'] > 0) & (df['fare_amount'] < 200)]\n",
    "    df = df[(df['trip_distance'] > 0) & (df['trip_distance'] < 50)]\n",
    "    df = df[df['passenger_count'] > 0]\n",
    "    \n",
    "    return df[feature_cols], df[target_col], feature_cols\n",
    "\n",
    "X, y, feature_cols = benchmark(prepare_features, 'feature_engineering')\n",
    "print(f\"\\nFeature shape: {X.shape}\")\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Operation: train_test_split\n",
      "Sure: 0.234 saniye\n",
      "Bellek: 0.34 MB\n",
      "==================================================\n",
      "\n",
      "Train: 400,000 samples\n",
      "Test: 100,000 samples\n"
     ]
    }
   ],
   "source": [
    "# Train/Test Split\n",
    "def split_data():\n",
    "    # Daha kucuk sample al (hiz icin)\n",
    "    sample_size = min(500000, len(X))\n",
    "    indices = np.random.choice(len(X), sample_size, replace=False)\n",
    "    \n",
    "    X_sampled = X.iloc[indices]\n",
    "    y_sampled = y.iloc[indices]\n",
    "    \n",
    "    return train_test_split(\n",
    "        X_sampled, y_sampled, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "X_train, X_test, y_train, y_test = benchmark(split_data, 'train_test_split')\n",
    "print(f\"\\nTrain: {len(X_train):,} samples\")\n",
    "print(f\"Test: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Operation: baseline_training\n",
      "Sure: 10.381 saniye\n",
      "Bellek: 161.74 MB\n",
      "==================================================\n",
      "\n",
      "Baseline Model Sonuclari:\n",
      "  RMSE: $3.78\n",
      "  MAE:  $1.81\n",
      "  R2:   0.9481\n"
     ]
    }
   ],
   "source": [
    "# Baseline: RandomForest\n",
    "def train_baseline():\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return {'rmse': rmse, 'mae': mae, 'r2': r2, 'model': model}\n",
    "\n",
    "baseline_result = benchmark(train_baseline, 'baseline_training')\n",
    "print(f\"\\nBaseline Model Sonuclari:\")\n",
    "print(f\"  RMSE: ${baseline_result['rmse']:.2f}\")\n",
    "print(f\"  MAE:  ${baseline_result['mae']:.2f}\")\n",
    "print(f\"  R2:   {baseline_result['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ray ile Paralel Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri Ray object store'a yuklendi\n"
     ]
    }
   ],
   "source": [
    "# Veriyi Ray object store'a koy\n",
    "X_train_ref = ray.put(X_train.values)\n",
    "y_train_ref = ray.put(y_train.values)\n",
    "X_test_ref = ray.put(X_test.values)\n",
    "y_test_ref = ray.put(y_test.values)\n",
    "\n",
    "print(\"Veri Ray object store'a yuklendi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ray remote ile model training\n",
    "@ray.remote\n",
    "def train_model_with_params(params, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Belirli parametrelerle model egit ve degerlendir\"\"\"\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_split=params['min_samples_split'],\n",
    "        random_state=42,\n",
    "        n_jobs=1  # Ray zaten paralellestiriyor\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'params': params,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test edilecek parametre kombinasyonu: 8\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = [\n",
    "    {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 2},\n",
    "    {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2},\n",
    "    {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2},\n",
    "    {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2},\n",
    "    {'n_estimators': 100, 'max_depth': 15, 'min_samples_split': 5},\n",
    "    {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 2},\n",
    "    {'n_estimators': 150, 'max_depth': 15, 'min_samples_split': 5},\n",
    "    {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 2},\n",
    "]\n",
    "\n",
    "print(f\"Test edilecek parametre kombinasyonu: {len(param_grid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paralel hyperparameter search basliyor...\n",
      "\n",
      "==================================================\n",
      "Operation: parallel_tuning\n",
      "Sure: 165.651 saniye\n",
      "Bellek: 0.37 MB\n",
      "==================================================\n",
      "\n",
      "En iyi parametreler: {'n_estimators': 150, 'max_depth': 15, 'min_samples_split': 5}\n",
      "En iyi RMSE: $3.73\n",
      "En iyi R2: 0.9497\n"
     ]
    }
   ],
   "source": [
    "# Paralel hyperparameter search\n",
    "def parallel_hyperparameter_search():\n",
    "    # Tum modelleri paralel calistir\n",
    "    futures = [\n",
    "        train_model_with_params.remote(\n",
    "            params, X_train_ref, y_train_ref, X_test_ref, y_test_ref\n",
    "        )\n",
    "        for params in param_grid\n",
    "    ]\n",
    "    # Sonuclari topla\n",
    "    results_list = ray.get(futures)\n",
    "    return results_list\n",
    "\n",
    "print(\"Paralel hyperparameter search basliyor...\")\n",
    "tuning_results = benchmark(parallel_hyperparameter_search, 'parallel_tuning')\n",
    "\n",
    "# En iyi modeli bul\n",
    "best_result = min(tuning_results, key=lambda x: x['rmse'])\n",
    "print(f\"\\nEn iyi parametreler: {best_result['params']}\")\n",
    "print(f\"En iyi RMSE: ${best_result['rmse']:.2f}\")\n",
    "print(f\"En iyi R2: {best_result['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TUM HYPERPARAMETER SONUCLARI\n",
      "================================================================================\n",
      "n_est    depth    split    RMSE ($)     MAE ($)      R2          \n",
      "--------------------------------------------------------------------------------\n",
      "150      15       5        3.73         1.72         0.9497      \n",
      "100      15       5        3.73         1.72         0.9495      \n",
      "50       10       2        3.78         1.81         0.9481      \n",
      "100      10       2        3.78         1.81         0.9481      \n",
      "150      10       2        3.78         1.81         0.9481      \n",
      "200      10       2        3.79         1.81         0.9480      \n",
      "100      5        2        4.12         2.11         0.9384      \n",
      "50       5        2        4.12         2.11         0.9384      \n"
     ]
    }
   ],
   "source": [
    "# Tum sonuclari goster\n",
    "print(\"\\nTUM HYPERPARAMETER SONUCLARI\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'n_est':<8} {'depth':<8} {'split':<8} {'RMSE ($)':<12} {'MAE ($)':<12} {'R2':<12}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "sorted_results = sorted(tuning_results, key=lambda x: x['rmse'])\n",
    "for r in sorted_results:\n",
    "    p = r['params']\n",
    "    print(f\"{p['n_estimators']:<8} {p['max_depth']:<8} {p['min_samples_split']:<8} {r['rmse']:<12.2f} {r['mae']:<12.2f} {r['r2']:<12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Seri vs Paralel Karsilastirma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seri hyperparameter search basliyor...\n",
      "\n",
      "==================================================\n",
      "Operation: serial_tuning\n",
      "Sure: 615.992 saniye\n",
      "Bellek: 5.67 MB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Seri hyperparameter search (karsilastirma icin)\n",
    "def serial_hyperparameter_search():\n",
    "    results_list = []\n",
    "    for params in param_grid:\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            min_samples_split=params['min_samples_split'],\n",
    "            random_state=42,\n",
    "            n_jobs=1\n",
    "        )\n",
    "        model.fit(X_train.values, y_train.values)\n",
    "        y_pred = model.predict(X_test.values)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        results_list.append({'params': params, 'rmse': rmse})\n",
    "    return results_list\n",
    "\n",
    "print(\"Seri hyperparameter search basliyor...\")\n",
    "serial_results = benchmark(serial_hyperparameter_search, 'serial_tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SERI vs PARALEL KARSILASTIRMA\n",
      "==================================================\n",
      "Seri:    615.99s\n",
      "Paralel: 165.65s\n",
      "Hizlanma: 3.7x\n"
     ]
    }
   ],
   "source": [
    "# Karsilastirma\n",
    "parallel_time = results['operations']['parallel_tuning']['duration_sec']\n",
    "serial_time = results['operations']['serial_tuning']['duration_sec']\n",
    "\n",
    "print(f\"\\nSERI vs PARALEL KARSILASTIRMA\")\n",
    "print(f\"=\"*50)\n",
    "print(f\"Seri:    {serial_time:.2f}s\")\n",
    "print(f\"Paralel: {parallel_time:.2f}s\")\n",
    "print(f\"Hizlanma: {serial_time/parallel_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Model ve Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FEATURE IMPORTANCE\n",
      "==================================================\n",
      "trip_distance        0.963 ################################################\n",
      "DOLocationID         0.018 \n",
      "PULocationID         0.008 \n",
      "pickup_hour          0.006 \n",
      "pickup_dayofweek     0.003 \n",
      "passenger_count      0.001 \n",
      "is_rush_hour         0.000 \n",
      "is_weekend           0.000 \n"
     ]
    }
   ],
   "source": [
    "# En iyi parametrelerle final model\n",
    "final_model = RandomForestRegressor(\n",
    "    **best_result['params'],\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFEATURE IMPORTANCE\")\n",
    "print(\"=\"*50)\n",
    "for _, row in importance_df.iterrows():\n",
    "    bar = '#' * int(row['importance'] * 50)\n",
    "    print(f\"{row['feature']:<20} {row['importance']:.3f} {bar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORNEK TAHMINLER\n",
      "======================================================================\n",
      "Distance     Hour     Actual ($)   Predicted ($)  Error ($) \n",
      "----------------------------------------------------------------------\n",
      "2.00         16       13.50        14.68          1.18      \n",
      "10.01        21       42.90        41.75          1.15      \n",
      "0.97         16       10.00        9.56           0.44      \n",
      "0.62         9        7.90         7.15           0.75      \n",
      "0.91         19       7.20         8.07           0.87      \n",
      "0.40         21       6.50         5.40           1.10      \n",
      "2.42         17       17.70        16.51          1.19      \n",
      "3.82         11       26.10        23.88          2.22      \n",
      "0.70         23       5.80         6.69           0.89      \n",
      "2.44         10       17.00        17.76          0.76      \n"
     ]
    }
   ],
   "source": [
    "# Ornekler uzerinde tahmin\n",
    "print(\"\\nORNEK TAHMINLER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sample_idx = np.random.choice(len(X_test), 10, replace=False)\n",
    "sample_X = X_test.iloc[sample_idx]\n",
    "sample_y = y_test.iloc[sample_idx]\n",
    "sample_pred = final_model.predict(sample_X)\n",
    "\n",
    "print(f\"{'Distance':<12} {'Hour':<8} {'Actual ($)':<12} {'Predicted ($)':<14} {'Error ($)':<10}\")\n",
    "print(\"-\"*70)\n",
    "for i in range(10):\n",
    "    error = abs(sample_y.iloc[i] - sample_pred[i])\n",
    "    print(f\"{sample_X.iloc[i]['trip_distance']:<12.2f} {int(sample_X.iloc[i]['pickup_hour']):<8} {sample_y.iloc[i]:<12.2f} {sample_pred[i]:<14.2f} {error:<10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sonuclari Kaydet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sonuclar kaydedildi: results/ray_benchmark.json\n",
      "\n",
      "{\n",
      "  \"framework\": \"ray\",\n",
      "  \"dataset\": \"nyc_taxi_12_months\",\n",
      "  \"operations\": {\n",
      "    \"parallel_file_stats\": {\n",
      "      \"duration_sec\": 3.146,\n",
      "      \"memory_mb\": 6.22\n",
      "    },\n",
      "    \"load_sample_data\": {\n",
      "      \"duration_sec\": 0.316,\n",
      "      \"memory_mb\": 566.91\n",
      "    },\n",
      "    \"feature_engineering\": {\n",
      "      \"duration_sec\": 2.979,\n",
      "      \"memory_mb\": 740.66\n",
      "    },\n",
      "    \"train_test_split\": {\n",
      "      \"duration_sec\": 0.234,\n",
      "      \"memory_mb\": 0.34\n",
      "    },\n",
      "    \"baseline_training\": {\n",
      "      \"duration_sec\": 10.381,\n",
      "      \"memory_mb\": 161.74\n",
      "    },\n",
      "    \"parallel_tuning\": {\n",
      "      \"duration_sec\": 165.651,\n",
      "      \"memory_mb\": 0.37\n",
      "    },\n",
      "    \"serial_tuning\": {\n",
      "      \"duration_sec\": 615.992,\n",
      "      \"memory_mb\": 5.67\n",
      "    }\n",
      "  },\n",
      "  \"total_memory_mb\": 2024.96,\n",
      "  \"total_memory_gb\": 1.98,\n",
      "  \"row_count\": 38310226,\n",
      "  \"best_params\": {\n",
      "    \"n_estimators\": 150,\n",
      "    \"max_depth\": 15,\n",
      "    \"min_samples_split\": 5\n",
      "  },\n",
      "  \"best_rmse\": 3.73,\n",
      "  \"best_r2\": 0.9497,\n",
      "  \"speedup\": 3.72\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results['total_memory_mb'] = round(get_memory_mb(), 2)\n",
    "results['total_memory_gb'] = round(get_memory_mb() / 1024, 2)\n",
    "results['row_count'] = int(total_rows)\n",
    "results['best_params'] = best_result['params']\n",
    "results['best_rmse'] = round(best_result['rmse'], 2)\n",
    "results['best_r2'] = round(best_result['r2'], 4)\n",
    "results['speedup'] = round(serial_time / parallel_time, 2)\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "with open('results/ray_benchmark.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Sonuclar kaydedildi: results/ray_benchmark.json\")\n",
    "print(\"\\n\" + json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Ray Ozet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAY AVANTAJLARI\n",
      "===============\n",
      "\n",
      "1. KOLAY PARALELLESTIRME\n",
      "   - @ray.remote dekoratoru\n",
      "   - ray.get() ile sonuc al\n",
      "   - Herhangi bir Python kodu paralel calisir\n",
      "\n",
      "2. OBJECT STORE\n",
      "   - ray.put() ile veri paylasimi\n",
      "   - Zero-copy data sharing\n",
      "   - Worker'lar arasi verimli iletisim\n",
      "\n",
      "3. RAY TRAIN\n",
      "   - Distributed model training\n",
      "   - XGBoost, PyTorch, TensorFlow destegi\n",
      "   - Checkpointing\n",
      "\n",
      "4. RAY TUNE\n",
      "   - Hyperparameter optimization\n",
      "   - Grid, Random, Bayesian search\n",
      "   - Early stopping, scheduling\n",
      "\n",
      "5. RAY SERVE\n",
      "   - Model serving at scale\n",
      "   - A/B testing\n",
      "   - Batch inference\n",
      "\n",
      "NE ZAMAN RAY?\n",
      "=============\n",
      "- ML model training/tuning\n",
      "- Hyperparameter optimization\n",
      "- Distributed Python uygulamalari\n",
      "- Model serving at scale\n",
      "- Reinforcement learning\n",
      "\n",
      "NE ZAMAN DASK?\n",
      "==============\n",
      "- DataFrame islemleri\n",
      "- ETL pipelines\n",
      "- Pandas-like workloads\n",
      "\n",
      "NE ZAMAN POLARS?\n",
      "================\n",
      "- Single-node maximum speed\n",
      "- Memory efficiency\n",
      "- Drop-in Pandas replacement\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "RAY AVANTAJLARI\n",
    "===============\n",
    "\n",
    "1. KOLAY PARALELLESTIRME\n",
    "   - @ray.remote dekoratoru\n",
    "   - ray.get() ile sonuc al\n",
    "   - Herhangi bir Python kodu paralel calisir\n",
    "\n",
    "2. OBJECT STORE\n",
    "   - ray.put() ile veri paylasimi\n",
    "   - Zero-copy data sharing\n",
    "   - Worker'lar arasi verimli iletisim\n",
    "\n",
    "3. RAY TRAIN\n",
    "   - Distributed model training\n",
    "   - XGBoost, PyTorch, TensorFlow destegi\n",
    "   - Checkpointing\n",
    "\n",
    "4. RAY TUNE\n",
    "   - Hyperparameter optimization\n",
    "   - Grid, Random, Bayesian search\n",
    "   - Early stopping, scheduling\n",
    "\n",
    "5. RAY SERVE\n",
    "   - Model serving at scale\n",
    "   - A/B testing\n",
    "   - Batch inference\n",
    "\n",
    "NE ZAMAN RAY?\n",
    "=============\n",
    "- ML model training/tuning\n",
    "- Hyperparameter optimization\n",
    "- Distributed Python uygulamalari\n",
    "- Model serving at scale\n",
    "- Reinforcement learning\n",
    "\n",
    "NE ZAMAN DASK?\n",
    "==============\n",
    "- DataFrame islemleri\n",
    "- ETL pipelines\n",
    "- Pandas-like workloads\n",
    "\n",
    "NE ZAMAN POLARS?\n",
    "================\n",
    "- Single-node maximum speed\n",
    "- Memory efficiency\n",
    "- Drop-in Pandas replacement\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray kapatildi.\n"
     ]
    }
   ],
   "source": [
    "# Ray'i kapat\n",
    "ray.shutdown()\n",
    "print(\"Ray kapatildi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sonraki Adim\n",
    "\n",
    "Tum framework'lerin karsilastirmasi:\n",
    "\n",
    "-> `05_karsilastirma.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
