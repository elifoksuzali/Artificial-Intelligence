{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkI1Uiy4aBg1","outputId":"ede323ec-0e9f-4e57-9c8d-9fb7ac40dd36","executionInfo":{"status":"ok","timestamp":1723056882742,"user_tz":-180,"elapsed":22422,"user":{"displayName":"elif oksuzali","userId":"14728913008743787906"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mounting my google drive in colab notebook\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"6oOkGlkkh2fG"},"outputs":[],"source":["# GEMİNİ GRAMMER DÜZELTpip install spacyturk\n","#!pip install https://huggingface.co/turkish-nlp-suite/tr_core_news_trf/resolve/main/tr_core_news_trf-any-py3-none-any.whl"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Ekz7hH_NH4YU","colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1723059754860,"user_tz":-180,"elapsed":427,"user":{"displayName":"elif oksuzali","userId":"14728913008743787906"}},"outputId":"d1d00745-d47e-4ad8-cac6-b6d22450ea1d"},"outputs":[{"output_type":"error","ename":"OSError","evalue":"[E050] Can't find model 'tr_core_news_trf'. It doesn't seem to be a Python package or a valid path to a data directory.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-734616cdd63e>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#nlp = spacy.load(\"en_core_web_sm\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tr_core_news_trf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE941\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOLD_MODEL_SHORTCUTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'tr_core_news_trf'. It doesn't seem to be a Python package or a valid path to a data directory."]}],"source":["import google.generativeai as genai\n","import pandas as pd\n","import time\n","import os\n","import spacy\n","\n","\n","# Google Generative AI API anahtarınızı ayarlayın\n","genai.configure(api_key=\"AIzaSyCHItAly9xAzZQlrybfa8bHXyoGvh_UPRY\") # Buraya Google Generative AI API anahtarınızı yerleştirin\n","\n","# Veri setlerinin bulunduğu klasör yolu\n","folder_path = \"/content/sikayetvar_comments_vodafone_page1_to_350.csv\"  # CSV dosyalarının bulunduğu klasörün tam yolunu belirtin\n","\n","# Model oluşturma\n","generation_config = {\n"," \"temperature\": 0.9,\n"," \"top_p\": 1,\n"," \"top_k\": 1,\n"," \"max_output_tokens\": 2048,\n","}\n","\n","safety_settings = [\n"," {\n"," \"category\": \"HARM_CATEGORY_HARASSMENT\",\n"," \"threshold\": \"BLOCK_NONE\"\n"," },\n","{\n"," \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n"," \"threshold\": \"BLOCK_NONE\"\n","},\n","{\n"," \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n"," \"threshold\": \"BLOCK_NONE\"\n","},\n","{\n"," \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n"," \"threshold\": \"BLOCK_NONE\"\n","}\n","]\n","\n","# spacy modeli yükleme\n","#nlp = spacy.load(\"en_core_web_sm\")\n","\n","nlp = spacy.load(\"tr_core_news_trf\")\n","\n","\n","# CSV dosyalarını oku ve işle\n","csv_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.csv')])\n","for file_num, file_name in enumerate(csv_files, start=1):\n","    print(f\"Şu an işlenen dosya: {file_name}\")\n","    df = pd.read_csv(os.path.join(folder_path, file_name))\n","\n","    results = []\n","    #for i, row in df.iloc[840:].iterrows(): çalıştır gitsin\n","    for i, row in df.iloc[886:].iterrows():\n","        tweet = row['yorum']\n","        # spacy ile cümleyi işle\n","        doc = nlp(tweet)\n","        # cümlenin uzunluğu 3'ten fazla ise olumlu-olumsuz etiketle\n","\n","        prompt = f\"\"\"Türkçe metinlerde dil bilgisini düzeltme ve yeni cümle halini oluşturmanı istiyorum.\n","        Sadece metni anlamlı olacak şekilde yeniden oluştur. Asla açıklama ekleme. Başlık ekleme\n","                         Türkçe metinlerdeki dil bilgisi hatalarını düzeltmek ve cümleleri\n","                         anlamlı bir şekilde yeniden yazmanı istiyorum. Metinleri sadece yeniden yapılandıracaksın,\n","                         açıklama ya da başlık eklemeyeceksin.\n","\n","             Yorum: {doc}\"\"\"\n","        response = genai.GenerativeModel(model_name=\"gemini-pro\",\n","                                             generation_config=generation_config,\n","                                             safety_settings=safety_settings\n","                                             ).generate_content(prompt)\n","        if response.text:\n","                   corrected_sentence = response.text\n","        else:\n","        # Check safety_ratings for blocked categories\n","            if any(rating['category'] in safety_settings and rating['rating'] in ['BLOCK_MEDIUM_AND_ABOVE', 'BLOCK_ONLY_HIGH'] for rating in response.candidate.safety_ratings):\n","                  corrected_sentence = \"Response blocked due to safety concerns.\"\n","            else:\n","                  corrected_sentence = \"No response\"\n","\n","\n","        results.append({'yorum': tweet, 'yeni_yorum': corrected_sentence})\n","        data = pd.DataFrame(results)\n","        a = data.to_csv(\"/content/drive/MyDrive/AISentiment/model/datto3.csv\", index=False)\n","        print(f\"{file_name} dosyası işlendi. Tahminler {a} dosyasına kaydedildi.\")\n","        print(f\"Yorum {i+1}/{len(df)} işlendi.\")\n","\n","        # API'ye aşırı yüklenmeyi önlemek için biraz bekleyin\n","        time.sleep(10)  # 5 saniye bekleme\n","\n","print(\"Tüm işlemler tamamlandı.\")\n"]},{"cell_type":"markdown","metadata":{"id":"TVU7F1sdB2Uc"},"source":["# CSV DİL DÜZELTME"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1U3DlVEOCAcI"},"outputs":[],"source":["#!pip install -q -U google-generativeai"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T71DBZf2pYfV"},"outputs":[],"source":["#!pip install openai==0.28"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ekUZQCgLk7Yc"},"outputs":[],"source":["#df8 türkçe metimlerden oluşan bir veri seti ve labels etiketi veriliyor\n","#df7 anlamlı bütün korunmamış ingilizce türkçe çeviri yapılan etiketli veri\n","#df7 önce anlamlı türkçe haline getir sonra etiket verilecek yeniden"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Cl3w9_2pXsi"},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_csv(\"/content/model/eskihotels.csv\")\n","\n","# İlk 100 satırı silmek için\n","df = df.drop(index=range(97))\n","\n","# İlk 100 satırı sildikten sonra kalan DataFrame'i gösterelim\n","print(df)\n","df.to_csv(\"/content/model/hotel.csv\",index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Dj_keo2dQ7uZ"},"outputs":[],"source":["# prompt: !python -m spacy download tr_core_news_md  for turkhis spacy language model\n","!pip install https://huggingface.co/turkish-nlp-suite/tr_core_news_trf/resolve/main/tr_core_news_trf-any-py3-none-any.whl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlgGG7z7QuyB"},"outputs":[],"source":["import spacy\n","\n","nlp = spacy.load(\"tr_core_news_trf\")\n","nlp.pipe_names"]},{"cell_type":"markdown","metadata":{"id":"8PFvaVN1QU_R"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":789,"status":"ok","timestamp":1715072515453,"user":{"displayName":"Elif Teknoarge","userId":"05202310017140846457"},"user_tz":-180},"id":"f_oL6Ud2SObi","outputId":"43490e31-6b76-4c9e-d579-1904bf9e733a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ben PRON nsubj ben Case=Nom|Number=Sing|Person=1\n","de CCONJ advmod:emph de \n","Ankara'ya PROPN obl Ankara Case=Dat|Number=Sing|Person=3\n","gittim VERB ROOT git Aspect=Perf|Evident=Fh|Number=Sing|Person=1|Polarity=Pos|Tense=Past\n",". PUNCT punct . \n"]}],"source":["sentence = \"Ben de Ankara'ya gittim.\"\n","doc = nlp(sentence)\n","for token in doc:\n","  print(token.text, token.pos_, token.dep_, token.lemma_, token.morph)"]},{"cell_type":"markdown","metadata":{"id":"YKZAxp8yP9uy"},"source":["#Veriyi Test Etmek\n","  \n","\n","*   BERT MODEL\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNP4_nrsP9V4"},"outputs":[],"source":["# Gerekli kütüphaneleri kur\n","!pip install pandas torch transformers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPCxodRxRIPC"},"outputs":[],"source":["import pandas as pd\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","import torch\n","\n","# Model ve tokenizer'ı yükle\n","tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n","\n","# Özel etiketler\n","custom_labels = {\n","    0: \"negatif\",\n","    1: \"nötr\",\n","    2: \"pozitif\"\n","\n","}\n","\n","# CSV dosyasından verileri okuyun\n","input_csv_path = \"/content/sikayetvar_comments_turkcell_page1_to_350.csv\"  # giriş dosyasının adı\n","output_csv_path = \"tahminler4.csv\"  # çıkış dosyasının adı\n","data = pd.read_csv(input_csv_path)\n","\n","# Yeni bir DataFrame oluşturmak için boş bir liste\n","results = []\n","\n","# Verileri döngü ile işleyin\n","for index, row in data.iterrows():\n","    sentence = row[\"comment\"]  # CSV'de yorum sütununu hedefleyin\n","\n","    # Tokenize etme ve tahmin yapma\n","    inputs = tokenizer(sentence, return_tensors='pt',max_length=200, truncation=True)\n","    outputs = model(**inputs)\n","\n","    # Logitlerden olasılıkları hesaplayın\n","    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n","\n","    # En yüksek olasılığa sahip olan sınıfı alın\n","    predicted_class = probabilities.argmax().item()\n","    predicted_label = custom_labels[predicted_class]\n","\n","    # Olasılık değeri\n","\n","    # Sonucu listeye ekleyin\n","    results.append({\n","        \"comment\": sentence,\n","        \"labels\": predicted_label,\n","    })\n","    results_df = pd.DataFrame(results)\n","    results_df.to_csv(output_csv_path, index=False)  # Indexsiz olarak CSV'ye yazdırın\n","    print(\"Tahminler başarıyla kaydedildi:\", output_csv_path)\n","    # İlerleme hakkında bilgi verin\n","    print(f\"{index + 1}/{len(data)} - {sentence} -> {predicted_label})\")\n","\n","# Tahmin sonuçlarını CSV'ye yazdırın\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eq1VFO16WFRQ"},"source":["# T3 VAKFI OTOMATİK SENTİMENT KODLAYICI"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9278,"status":"ok","timestamp":1722894079704,"user":{"displayName":"elif oksuzali","userId":"14728913008743787906"},"user_tz":-180},"id":"pDMd-nt7dIsF","outputId":"1f0d165d-0fee-42f0-9b1b-5feaa055f741"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.17.0\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2pQc-UuFcTs"},"outputs":[],"source":["import google.generativeai as genai\n","import pandas as pd\n","import time\n","import os\n","import spacy\n","\n","# Google Generative AI API anahtarınızı ayarlayın\n","genai.configure(api_key=\"AIzaSyCHItAly9xAzZQlrybfa8bHXyoGvh_UPRY\")  # Buraya Google Generative AI API anahtarınızı yerleştirin\n","\n","# Veri setlerinin bulunduğu klasör yolu\n","folder_path = \"/content/sikayetvar_comments_turkcell_page1_to_350.csv\"  # CSV dosyalarının bulunduğu klasörün tam yolunu belirtin\n","\n","# Model oluşturma\n","generation_config = {\n","    \"temperature\": 0.9,\n","    \"top_p\": 1,\n","    \"top_k\": 1,\n","    \"max_output_tokens\": 2048,\n","}\n","\n","safety_settings = [\n","    {\n","        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n","        \"threshold\": \"BLOCK_NONE\"\n","    },\n","    {\n","        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n","        \"threshold\": \"BLOCK_NONE\"\n","    },\n","    {\n","        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n","        \"threshold\": \"BLOCK_NONE\"\n","    },\n","    {\n","        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n","        \"threshold\": \"BLOCK_NONE\"\n","    }\n","]\n","\n","# spacy modeli yükleme\n","nlp = spacy.load(\"en_core_web_trf\")\n","\n","# CSV dosyalarını oku ve işle\n","csv_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.csv')])\n","for file_num, file_name in enumerate(csv_files, start=1):\n","    print(f\"Şu an işlenen dosya: {file_name}\")\n","    df = pd.read_csv(os.path.join(folder_path, file_name))\n","\n","    results = []\n","    for i, row in df.iterrows():\n","        tweet = row['yorum']\n","        # spacy ile cümleyi işle\n","        doc = nlp(tweet)\n","\n","        # Yorumun uzunluğu 3'ten fazla ise işlem yap\n","        if len(doc) > 3:\n","            prompt = f\"\"\"Aşağıdaki Türkçe metin için duygu analizi yapmanızı istiyorum. Metni okuyun ve \"olumlu\", \"nötr\" veya \"olumsuz\" olarak etiketleyin.\n","            Metin: {tweet}\"\"\"\n","\n","            response = genai.GenerativeModel(model_name=\"gemini-pro\").generate(prompt=prompt, **generation_config)\n","\n","            sentiment = response.generations[0].text.strip() if response.generations else \"No response\"\n","\n","            # Check safety ratings for blocked categories\n","            if any(rating['category'] in safety_settings and rating['rating'] in ['BLOCK_MEDIUM_AND_ABOVE', 'BLOCK_ONLY_HIGH'] for rating in response.generations[0].safety_ratings):\n","                sentiment = \"Response blocked due to safety concerns.\"\n","\n","            results.append({'yorum': tweet, 'duygu_durumu': sentiment})\n","\n","        # API'ye aşırı yüklenmeyi önlemek için biraz bekleyin\n","        time.sleep(10)  # 10 saniye bekleme\n","\n","    data = pd.DataFrame(results)\n","    output_file_path = os.path.join(\"/content/model\", f\"processed_{file_name}\")\n","    data.to_csv(output_file_path, index=False)\n","    print(f\"{file_name} dosyası işlendi. Tahminler {output_file_path} dosyasına kaydedildi.\")\n","\n","print(\"Tüm işlemler tamamlandı.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O0h_EreOav-W"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["TVU7F1sdB2Uc"],"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}