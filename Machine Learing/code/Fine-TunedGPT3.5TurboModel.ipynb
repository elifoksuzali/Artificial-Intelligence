{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OS7xqlAT9V4b_1eDO3XfFuRHKX5Vr3XX","timestamp":1697113696264}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SVoU7VrzGzxn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697447700445,"user_tz":-180,"elapsed":22332,"user":{"displayName":"Elif Teknoarge","userId":"05202310017140846457"}},"outputId":"8cd968b1-bf3e-47fc-fcbe-81e801318f50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n","Installing collected packages: openai\n","Successfully installed openai-0.28.1\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Collecting tiktoken\n","  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.5.1\n","Collecting Gradio\n","  Downloading gradio-3.47.1-py3-none-any.whl (20.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from Gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (4.2.2)\n","Collecting fastapi (from Gradio)\n","  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from Gradio)\n","  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.6.0 (from Gradio)\n","  Downloading gradio_client-0.6.0-py3-none-any.whl (298 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from Gradio)\n","  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub>=0.14.0 (from Gradio)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from Gradio) (6.1.0)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (1.23.5)\n","Collecting orjson~=3.0 (from Gradio)\n","  Downloading orjson-3.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from Gradio) (23.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (1.5.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (9.4.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from Gradio) (1.10.13)\n","Collecting pydub (from Gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart (from Gradio)\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (6.0.1)\n","Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (2.31.0)\n","Collecting semantic-version~=2.0 (from Gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from Gradio) (4.5.0)\n","Collecting uvicorn>=0.14.0 (from Gradio)\n","  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets<12.0,>=10.0 (from Gradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.6.0->Gradio) (2023.6.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->Gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->Gradio) (4.19.1)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->Gradio) (0.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->Gradio) (3.12.4)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->Gradio) (4.66.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->Gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->Gradio) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->Gradio) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->Gradio) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->Gradio) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->Gradio) (2023.7.22)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->Gradio) (8.1.7)\n","Collecting h11>=0.8 (from uvicorn>=0.14.0->Gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->Gradio) (3.7.1)\n","Collecting starlette<0.28.0,>=0.27.0 (from fastapi->Gradio)\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpcore<0.19.0,>=0.18.0 (from httpx->Gradio)\n","  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->Gradio) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->Gradio) (1.1.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (0.10.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->Gradio) (1.16.0)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=c628960ec2940265ee7e5028df72e712490b5869ce7bb6eeb3cfc8ee82c1a7a6\n","  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, semantic-version, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, huggingface-hub, httpcore, httpx, fastapi, gradio-client, Gradio\n","Successfully installed Gradio-3.47.1 aiofiles-23.2.1 fastapi-0.103.2 ffmpy-0.3.1 gradio-client-0.6.0 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.18.0 orjson-3.9.9 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uvicorn-0.23.2 websockets-11.0.3\n"]}],"source":["!pip install openai\n","!pip install numpy\n","!pip install tiktoken\n","!pip install Gradio"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"CgU--G6j7otC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697447555830,"user_tz":-180,"elapsed":17771,"user":{"displayName":"Elif Teknoarge","userId":"05202310017140846457"}},"outputId":"8ca267c6-6fa0-45fb-e2e1-b2d1d2708cea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import openai\n","import csv\n","import json\n","import os\n","import numpy as np\n","from collections import defaultdict\n","import tiktoken\n","import gradio as gr\n","import time"],"metadata":{"id":"WysuPFYQHfCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","openai.api_key = \"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\" # Openai anahtarı"],"metadata":{"id":"_ofhSD5BII1W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Veri setini yüklüyoruz\n","csv_file_path = '/content/DataTrainColab.csv'\n","cleaned_data = []\n","\n","with open(csv_file_path, 'r', encoding='utf-8-sig') as file:\n","    csv_reader = csv.reader(file)\n","    for row in csv_reader:\n","        for cell in row:\n","            try:\n","\n","                cell = cell.replace('[\"', '').replace('\"]', '').replace('\\\\\"', '\"')\n","\n","                # json dosyasına uygun format haline getiriyoruz\n","                cell_json = json.loads(cell)\n","\n","\n","                cleaned_data.append(cell_json)\n","            except json.JSONDecodeError as e:\n","                print(f\"JSON  formatına çevrilmedi '{cell}': {e}\")\n","\n","jsonl_file_path = '/content/DataTrainColab.jsonl'\n","# Jsonl fine-tuning için gerekli olan format tipidir. Çeviri tamamlandığıktan sonra kadediyoruz\n","with open(jsonl_file_path, 'w', encoding='utf-8') as jsonl_file:\n","    for item in cleaned_data:\n","        jsonl_file.write(json.dumps(item) + '\\n')"],"metadata":{"id":"ySonCJu2I1KD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = '/content/DataTrainColab.jsonl'\n","\n","with open(data_path) as f:\n","    dataset = [json.loads(line) for line in f]\n","\n","print(\"Num examples:\", len(dataset))\n","print(\"First example:\")\n","for message in dataset[0][\"messages\"]:\n","    print(message)\n","\n","# Veri setinin yapısını kontrol amaçlı görüntülüyoruz\n","\n","format_errors = defaultdict(int)\n","\n","for ex in dataset:\n","    if not isinstance(ex, dict):\n","        format_errors[\"data_type\"] += 1\n","        continue\n","\n","    messages = ex.get(\"messages\", None)\n","    if not messages:\n","        format_errors[\"missing_messages_list\"] += 1\n","        continue\n","\n","    for message in messages:\n","        if \"role\" not in message or \"content\" not in message:\n","            format_errors[\"message_missing_key\"] += 1\n","\n","        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n","            format_errors[\"message_unrecognized_key\"] += 1\n","\n","        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n","            format_errors[\"unrecognized_role\"] += 1\n","\n","        content = message.get(\"content\", None)\n","        if not content or not isinstance(content, str):\n","            format_errors[\"missing_content\"] += 1\n","\n","    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n","        format_errors[\"example_missing_assistant_message\"] += 1\n","\n","if format_errors:\n","    print(\"Hata bulundu:\")\n","    for k, v in format_errors.items():\n","        print(f\"{k}: {v}\")\n","else:\n","    print(\"Hata bulunamadı\")\n","\n","# Mesajın yapısının ötesinde, uzunluğunun 4096 token sınırını aşmamasını da kontrol etmemiz gerekmetedir.\n","\n","# Jeton sayma fonksiyonları\n","encoding = tiktoken.get_encoding(\"cl100k_base\")\n","\n","\n","def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n","    num_tokens = 0\n","    for message in messages:\n","        num_tokens += tokens_per_message\n","        for key, value in message.items():\n","            num_tokens += len(encoding.encode(value))\n","            if key == \"name\":\n","                num_tokens += tokens_per_name\n","    num_tokens += 3\n","    return num_tokens\n","\n","def num_assistant_tokens_from_messages(messages):\n","    num_tokens = 0\n","    for message in messages:\n","        if message[\"role\"] == \"assistant\":\n","            num_tokens += len(encoding.encode(message[\"content\"]))\n","    return num_tokens\n","\n","def print_distribution(values, name):\n","    print(f\"\\n#### Distribution of {name}:\")\n","    print(f\"min / max: {min(values)}, {max(values)}\")\n","    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n","    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n","\n","\n","n_missing_system = 0\n","n_missing_user = 0\n","n_messages = []\n","convo_lens = []\n","assistant_message_lens = []\n","\n","for ex in dataset:\n","    messages = ex[\"messages\"]\n","    if not any(message[\"role\"] == \"system\" for message in messages):\n","        n_missing_system += 1\n","    if not any(message[\"role\"] == \"user\" for message in messages):\n","        n_missing_user += 1\n","    n_messages.append(len(messages))\n","    convo_lens.append(num_tokens_from_messages(messages))\n","    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n","\n","print(\"Sistem mesajı eksik olan örnek sayısı:\", n_missing_system) # eksik veya hatalı mesaj gövdeleri için\n","print(\"Eksik kullanıcı mesajı örneği sayısı:\", n_missing_user)\n","print_distribution(n_messages, \"örnek başına mesaj sayısı\")\n","print_distribution(convo_lens, \"örnek başına toplam jeton sayısı\")\n","print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n","n_too_long = sum(l > 4096 for l in convo_lens)\n","print(f\"\\n{n_too_long} örnekler 4096 jeton sınırının üzerinde olabilir; öyle ise fine tuning ayar sırasında kesilecektir\")\n","\n","# Fiyatlandırma ve varsayılan n_epochs tahmini\n","MAX_TOKENS_PER_EXAMPLE = 4096\n","\n","MIN_TARGET_EXAMPLES = 100\n","MAX_TARGET_EXAMPLES = 25000\n","TARGET_EPOCHS = 3\n","MIN_EPOCHS = 1\n","MAX_EPOCHS = 25\n","\n","n_epochs = TARGET_EPOCHS\n","n_train_examples = len(dataset)\n","if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n","    n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n","elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n","    n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n","\n","n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n","print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n","print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n","print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n","\n","# İnce ayar için tahmini maliyeti hesaplayın\n","cost_per_100k_tokens = 0.80  # Her 100.000 jetonun maliyeti\n","estimated_cost = ((n_epochs * n_billing_tokens_in_dataset) / 100000) * cost_per_100k_tokens\n","print(f\"İnce ayar için tahmini maliyet: yaklaşık ${estimated_cost:.2f}\") #Bunu veri setinde ne kadar ortalama jeton kullanacağına dair hesaplamayı görüyoruz ki (jeton yükleme bilgisi için önemli)"],"metadata":{"id":"-NNdePOiKuKW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697118472945,"user_tz":-180,"elapsed":5,"user":{"displayName":"Elif Teknoarge","userId":"05202310017140846457"}},"outputId":"e55cf75f-ab0d-4e1b-b8b6-713d397c4e83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num examples: 130\n","First example:\n","{'role': 'user', 'content': 'Satış Ekranları'}\n","{'role': 'assistant', 'content': 'acente2 programı içerisinde otel, tur, transfer, uçak bileti ve ekstra hizmetler olmak üzere 5 kalem ürün satışı yapılabilir. ekstra hizmetler dışındaki tüm ürünleri daha önceden operasyon ekranlarından tanımlanması gerekmektedir. aşağıda satış bölümü ile ilgili tüm detaylar bölümler halinde anlatılmaktadır.'}\n","No errors found\n","Num examples missing system message: 130\n","Num examples missing user message: 0\n","\n","#### Distribution of num_messages_per_example:\n","min / max: 2, 2\n","mean / median: 2.0, 2.0\n","p5 / p95: 2.0, 2.0\n","\n","#### Distribution of num_total_tokens_per_example:\n","min / max: 38, 893\n","mean / median: 199.73076923076923, 153.0\n","p5 / p95: 61.7, 457.50000000000006\n","\n","#### Distribution of num_assistant_tokens_per_example:\n","min / max: 15, 873\n","mean / median: 170.63846153846154, 115.5\n","p5 / p95: 33.8, 425.8000000000002\n","\n","0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n","Dataset has ~25965 tokens that will be charged for during training\n","By default, you'll train for 3 epochs on this dataset\n","By default, you'll be charged for ~77895 tokens\n","Estimated cost for fine-tuning: approximately $0.62\n"]}]},{"cell_type":"code","source":["# JSONL kopyalarını Google Drive'kaydedeceğimiz yolu gösteriyoruz\n","def save_to_jsonl(conversations, file_path):\n","    with open(file_path, 'w') as file:\n","        for conversation in conversations:\n","            json_line = json.dumps(conversation)\n","            file.write(json_line + '\\n')\n","\n","# JSONL dosyasını Google Drive'ınıza kaydetmek istediğimiz yolu belirti\n","jsonl_file_path = '/content/DataTrainColab.jsonl'\n","# Veri setini ve yolunu kadediyoruz\n","save_to_jsonl(dataset, jsonl_file_path)"],"metadata":{"id":"GME1BGqXNGMQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dosyayı eğitim için yüklüyoruz\n","training_file_name = '/content/DataTrainColab.jsonl'\n","\n","training_response = openai.File.create(\n","    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",")\n","training_file_id = training_response[\"id\"]\n","\n","#Eğitim dosyası kimliğini verir\n","print(\"Training file id:\", training_file_id)"],"metadata":{"id":"d403QpVVN3BU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697118497259,"user_tz":-180,"elapsed":1479,"user":{"displayName":"Elif Teknoarge","userId":"05202310017140846457"}},"outputId":"b1db574a-1775-4152-e160-e4942ee47781"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training file id: file-Q5zrEe5WTuEQV8YUNnfD2FAR\n"]}]},{"cell_type":"code","source":["# Fine-Tuning işlemini oluşturuyoruz\n","suffix_name = \"chatner-bot-elif\" #eğitelen modelimizin ismi (istediğiniz ismi verebilirsiniz api tarafında bu isimle modeli kontrol edebilirsiniz)\n","response = openai.FineTuningJob.create(\n","    training_file=training_file_id,\n","    model=\"gpt-3.5-turbo\",\n","    suffix=suffix_name,\n",")\n","job_id = response[\"id\"]\n","\n","print(response)"],"metadata":{"id":"SlZEZYGTOY-L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697118608977,"user_tz":-180,"elapsed":833,"user":{"displayName":"Elif Teknoarge","userId":"05202310017140846457"}},"outputId":"cf7f802d-9434-4ba0-ff3e-7937de2128b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"object\": \"fine_tuning.job\",\n","  \"id\": \"ftjob-NNiT0EbZbiLpHA0Z98vlnrt6\",\n","  \"model\": \"gpt-3.5-turbo-0613\",\n","  \"created_at\": 1697118608,\n","  \"finished_at\": null,\n","  \"fine_tuned_model\": null,\n","  \"organization_id\": \"org-ScTb5QZzhMRkAo0LqQ34DTaG\",\n","  \"result_files\": [],\n","  \"status\": \"validating_files\",\n","  \"validation_file\": null,\n","  \"training_file\": \"file-Q5zrEe5WTuEQV8YUNnfD2FAR\",\n","  \"hyperparameters\": {\n","    \"n_epochs\": \"auto\"\n","  },\n","  \"trained_tokens\": null,\n","  \"error\": null\n","}\n"]}]},{"cell_type":"code","source":["#FineTuning ilerledikçe loss (kayıpları)  ve dosya isimlerini listeleyerek takip ediyoruz\n","response = openai.FineTuningJob.list_events(id=job_id, limit=50)\n","\n","events = response[\"data\"]\n","events.reverse()\n","\n","for event in events:\n","    print(event[\"message\"])"],"metadata":{"id":"1Xyzue2SPYaZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697180839260,"user_tz":-180,"elapsed":849,"user":{"displayName":"Elif Teknoarge","userId":"05202310017140846457"}},"outputId":"8b9a0739-5a08-43af-cc5d-f8730189d391"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Created fine-tuning job: ftjob-NNiT0EbZbiLpHA0Z98vlnrt6\n","Validating training file: file-Q5zrEe5WTuEQV8YUNnfD2FAR\n","Files validated, moving job to queued state\n","Fine-tuning job started\n","Step 1/390: training loss=1.91\n","Step 11/390: training loss=2.08\n","Step 21/390: training loss=1.45\n","Step 31/390: training loss=1.90\n","Step 41/390: training loss=1.75\n","Step 51/390: training loss=2.02\n","Step 61/390: training loss=1.46\n","Step 71/390: training loss=1.94\n","Step 81/390: training loss=1.31\n","Step 91/390: training loss=2.15\n","Step 101/390: training loss=1.10\n","Step 111/390: training loss=1.33\n","Step 121/390: training loss=1.79\n","Step 131/390: training loss=1.34\n","Step 141/390: training loss=0.91\n","Step 151/390: training loss=1.48\n","Step 161/390: training loss=1.45\n","Step 171/390: training loss=1.94\n","Step 181/390: training loss=1.07\n","Step 191/390: training loss=1.17\n","Step 201/390: training loss=1.18\n","Step 211/390: training loss=1.12\n","Step 221/390: training loss=1.56\n","Step 231/390: training loss=2.19\n","Step 241/390: training loss=0.87\n","Step 251/390: training loss=1.70\n","Step 261/390: training loss=0.94\n","Step 271/390: training loss=1.37\n","Step 281/390: training loss=1.06\n","Step 291/390: training loss=0.76\n","Step 301/390: training loss=1.22\n","Step 311/390: training loss=1.08\n","Step 321/390: training loss=0.95\n","Step 331/390: training loss=1.06\n","Step 341/390: training loss=0.61\n","Step 351/390: training loss=0.98\n","Step 361/390: training loss=1.63\n","Step 371/390: training loss=0.77\n","Step 381/390: training loss=1.14\n","New fine-tuned model created: ft:gpt-3.5-turbo-0613:elif:chatner-bot-elif:88qb2ws4\n","The job has successfully completed\n"]}]},{"cell_type":"code","source":["# Onay mesajı gelince çalıştıracağımız bloklar (Siz artık bir modeli eğitip OpenAI tarafında yükleme işlemini gerçekleştirdiniz OpenAI sizin modelinizi kabul etmek\n","# için ortalama 1-24 saat arasında openapi kaydolduğunuz  mail adresiniz ne ise oraya bilgileri gönderecektir onay mesajı geldiğinde aşağaıdaki kodu çalıştırabilirsiniz)\n","# Fine-Tuning model kimliğini alıyoruz\n","\n","response = openai.FineTuningJob.retrieve(job_id)\n","fine_tuned_model_id = response[\"fine_tuned_model\"]\n","\n","print(response)\n","print(\"\\nFine-tuned model id:\", fine_tuned_model_id)\n","\n"],"metadata":{"id":"QUgVjlQxUMhw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697180855057,"user_tz":-180,"elapsed":335,"user":{"displayName":"Elif Teknoarge","userId":"05202310017140846457"}},"outputId":"93238c75-eaca-44ed-a25a-af6860883193"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"object\": \"fine_tuning.job\",\n","  \"id\": \"ftjob-NNiT0EbZbiLpHA0Z98vlnrt6\",\n","  \"model\": \"gpt-3.5-turbo-0613\",\n","  \"created_at\": 1697118608,\n","  \"finished_at\": 1697119495,\n","  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:elif:chatner-bot-elif:88qb2ws4\",\n","  \"organization_id\": \"org-ScTb5QZzhMRkAo0LqQ34DTaG\",\n","  \"result_files\": [\n","    \"file-GkrTJCiJw0hl4qOJI4aWpJLD\"\n","  ],\n","  \"status\": \"succeeded\",\n","  \"validation_file\": null,\n","  \"training_file\": \"file-Q5zrEe5WTuEQV8YUNnfD2FAR\",\n","  \"hyperparameters\": {\n","    \"n_epochs\": 3\n","  },\n","  \"trained_tokens\": 77115,\n","  \"error\": null\n","}\n","\n","Fine-tuned model id: ft:gpt-3.5-turbo-0613:elif:chatner-bot-elif:88qb2ws4\n"]}]},{"cell_type":"code","source":["#T ChatBot test etmeye başlayabiliriz!\n","\n","fine_tuned_model_id =\"ft:gpt-3.5-turbo-0613:elif:chatner-bot-elif:88qb2ws4\"\n","test_messages = []\n","\n","system_message = \"Curi Acente2 firmasının sağladığı hizmetlerden kaynaklı müşterilerden A2Admin paneli ve diğer programlar için gelen sorulara yanıt verir.\" # sistem neye hizmet ediyo,dilerseniz yazmayadabilirsiniz\n","test_messages.append({\"role\": \"system\", \"content\": system_message})\n","user_message = \"İnternet sitemize Jivo Chat programını ayarlar içerisindeki uzun metinler kısmında body etkiketinin üstüne mi ekliyoruz\" #sorulan soru\n","test_messages.append({\"role\": \"user\", \"content\": user_message})\n","\n","print(test_messages)"],"metadata":{"id":"8L7IEZScVi62","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697447966739,"user_tz":-180,"elapsed":417,"user":{"displayName":"Elif Teknoarge","userId":"05202310017140846457"}},"outputId":"4186e611-21ba-427b-f8a2-0db35835369e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'role': 'system', 'content': 'Curi Acente2 firmasının sağladığı hizmetlerden kaynaklı müşterilerden A2Admin paneli ve diğer programlar için gelen sorulara yanıt verir.'}, {'role': 'user', 'content': 'İnternet sitemize Jivo Chat programını ayarlar içerisindeki uzun metinler kısmında body etkiketinin üstüne mi ekliyoruz'}]\n"]}]},{"cell_type":"code","source":["#OpenAI Sohbet Tamamalanıyor\n","response = openai.ChatCompletion.create(\n","    model=fine_tuned_model_id, # Kendi modelimizi eğitime gönderiyoruz eğer aralarındaki farkı görmek istorsak model= gpt-3.5-turbo'ya göndererek test işlemini yapıp modellerin cevaplarını test edebiliriz\n","    messages=test_messages,\n","    temperature=0,\n","    max_tokens=1500\n",")\n","print(response[\"choices\"][0][\"message\"][\"content\"]) # Sorduğumuz soruya verdiği yanıtı console görmek istediğimizde burası o çıktıyı ekrana verir"],"metadata":{"id":"AJ2FtN_IVyxC","executionInfo":{"status":"ok","timestamp":1697447969006,"user_tz":-180,"elapsed":1202,"user":{"displayName":"Elif Teknoarge","userId":"05202310017140846457"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ddc3917-eab8-4f79-fc4d-07f54a0a9f11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Jivo Chat programınızı eklemek için aşağıdaki adımları takip edebilirsiniz. 1- A2admin paneli > Site Yönetimi > Ayarlar > Uzun Metinler > Body etiketinin üstüne ekleyeceğiniz kodu ekleyebilirsiniz.\n"]}]},{"cell_type":"code","source":["!pip install -q gradio # Pythonda bir arayüz ile görmek isterseniz bu kütüphaneyi kurmanız yeterli olacaktır."],"metadata":{"id":"iNEdkZLI4pCe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Gradio Arayüzü\n","def generate_completion(user_prompt):\n","    hidden_context = \"\"\n","    messages = [\n","        {\"role\": \"system\", \"content\": hidden_context},\n","        {\"role\": \"user\", \"content\": user_prompt}\n","    ]\n","    #Modele cevap üretmesini kendi eğitilmiş modelimizi referans alarak sorduğumuz soruya yanıt bekliyoruz\n","    response = openai.ChatCompletion.create(\n","        model=fine_tuned_model_id,\n","        messages=messages,\n","        max_tokens=1500,\n","        temperature=0\n","    )\n","    return response['choices'][0]['message']['content'].strip() # gelen cevap\n","\n","# Arayüzde nasıl gözükecek belirtiyoruz\n","\n","def replace(text):\n","    return text.replace('World', 'Databricks')\n","\n","gr.Interface(fn=generate_completion,\n","             inputs='textbox',\n","             outputs='textbox').launch(share=True);\n","\n","\n","############################# 2. ARAYÜZ İLE GÖSTERME YÖNTEMİ (SÜRÜM KONTROL YAPMAYI UNUTMAYIN => hatalı bir arayüz çıkaracağı için tercih 2.plandadır ilave ayar istediği için) #######################################ü\n","\n","\n","###iface = gr.Interface(fn=generate_completion,\n","                    # inputs=gr.inputs.Textbox(lines=5, placeholder='Acente2 Yazılımları Hakkında Destek?'),\n","                    #  outputs='text',\n","                    # title=\"Acente2 Yapay Zeka Asistanı\",\n","                    # input_labels=\"Question\",\n","                    # output_labels=\"Response\")\n","\n","###iface.launch(share=True)\n","\n","\n","# Jivo Chat programını Uzun metinler kısmında <body> tag üstüne mi ekliyoruz"],"metadata":{"id":"TjYFpQkDWsQQ"},"execution_count":null,"outputs":[]}]}